


<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">

        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta name="keywords" content="tensor learning, tensor decomposition, tensor operations">
        <meta name="description" content="TensorLy: Tensor learning in Python">

        
        <meta name="author" content="Jean Kossaifi">
        <title>TensorLy: Tensor learning in Python</title>
        

        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="../_static/bulma.min.css" />
        <link rel="stylesheet" type="text/css" href="../_static/base.min.css" />
        <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

        
        

        
        
    </head>

    <body>
        
        <nav class="navbar is-dark has-shadow top" id="top">
    <div class="navbar-brand">
        <a class="navbar-item navbar-title" href="../home.html">
            TensorLy
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="../index.html">
            <i class="fa fa-home" aria-hidden="true"></i>
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
            <span class="icon"><i class="fa fa-github"></i></span>
        </a>

		<span class="navbar-burger" data-target="NavbarMenu" >
			<span></span>
			<span></span>
			<span></span>
		</span>

    </div>

	<div id="NavbarMenu" class="navbar-menu">
		<div class="navbar-start">

			<a class="navbar-item" href="../installation.html">
				Install
			</a>
			<a class="navbar-item" href="../user_guide/index.html">
				User guide
			</a>
			<a class="navbar-item" href="#">
				API
			</a>
			<a class="navbar-item" href="../auto_examples/index.html">
				Examples
			</a>
			<a class="navbar-item" href="../authors.html">
				People
			</a>
			<a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
				Notebooks
			</a>

		</div>

		<div class="navbar-end">
			<a class="navbar-item is-tab tooltip is-hidden-touch" href="../index.html">
				<i class="fa fa-home" aria-hidden="true"></i>
				<span class="tooltiptext">Home page</span>
			</a>

			<a class="navbar-item is-tab tooltip is-hidden-touch" href="https://github.com/tensorly/tensorly" target="_blank">
				<span class="tooltiptext">Open project on Github</span>
				<span class="icon"><i class="fa fa-github"></i></span>
			</a>

		</div>
    </div>
</nav>
 

        
        <div class="columns">
            
            <div class="column is-one-quarter is-hidden-mobile aside">
                <div class="sidebar" id="sidebar">
                    
                    <div class="search">
                        <div class="search-title">
                            Search in TensorLy
                        </div>

                        <script>
                          (function() {
                            var cx = '002285679029256671182:5tfqz3cvmm8';
                            var gcse = document.createElement('script');
                            gcse.type = 'text/javascript';
                            gcse.async = true;
                            gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
                            var s = document.getElementsByTagName('script')[0];
                            s.parentNode.insertBefore(gcse, s);
                          })();
                        </script>
                        <gcse:searchbox-only></gcse:searchbox-only>
                        
                    </div>

                    <div class="toc">
                    
                    
                    
                    
                        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installing tensorly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/index.html">User guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#tensorly-manipulating-the-backend-with-a-unified-interface"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>: Manipulating the backend with a unified interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.set_backend.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.set_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.get_backend.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.get_backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.context.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.context</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.is_tensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.is_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.shape.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.shape</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.ndim.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.ndim</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.to_numpy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.to_numpy</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.copy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.copy</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.concatenate.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.concatenate</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.reshape.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.reshape</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.transpose.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.transpose</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.moveaxis.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.moveaxis</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.arange.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.arange</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.ones.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.ones</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.zeros.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.zeros</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.zeros_like.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.zeros_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.eye.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.eye</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.where.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.where</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.clip.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.clip</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.max.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.max</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.min.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.min</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.all.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.all</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.mean.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.mean</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.sum.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.sum</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.prod.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.prod</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.sign.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.sign</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.abs.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.abs</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.sqrt.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.sqrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.norm.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.dot.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.dot</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.kron.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.kron</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.solve.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.solve</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.qr.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.qr</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.kr.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.kr</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.partial_svd.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code>.partial_svd</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.base"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code>: Core tensor functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.base.unfold.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code>.unfold</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.base.fold.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code>.fold</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.base.tensor_to_vec.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code>.tensor_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.base.vec_to_tensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code>.vec_to_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.base.partial_unfold.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code>.partial_unfold</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.base.partial_fold.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code>.partial_fold</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.base.partial_tensor_to_vec.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code>.partial_tensor_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.base.partial_vec_to_tensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code>.partial_vec_to_tensor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.kruskal_tensor"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.kruskal_tensor</span></code>: Tensors in the Kruskal format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.kruskal_tensor.kruskal_to_tensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.kruskal_tensor</span></code>.kruskal_to_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.kruskal_tensor.kruskal_to_unfolded.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.kruskal_tensor</span></code>.kruskal_to_unfolded</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.kruskal_tensor.kruskal_to_vec.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.kruskal_tensor</span></code>.kruskal_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.kruskal_tensor.kruskal_mode_dot.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.kruskal_tensor</span></code>.kruskal_mode_dot</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.kruskal_tensor.unfolding_dot_khatri_rao.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.kruskal_tensor</span></code>.unfolding_dot_khatri_rao</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.tucker_tensor"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tucker_tensor</span></code>: Tensors in Tucker format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tucker_tensor.tucker_to_tensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tucker_tensor</span></code>.tucker_to_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tucker_tensor.tucker_to_unfolded.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tucker_tensor</span></code>.tucker_to_unfolded</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tucker_tensor.tucker_to_vec.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tucker_tensor</span></code>.tucker_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tucker_tensor.tucker_mode_dot.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tucker_tensor</span></code>.tucker_mode_dot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.mps_tensor"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.mps_tensor</span></code>: Tensors in Matrix-Product-State format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.mps_tensor.mps_to_tensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.mps_tensor</span></code>.mps_to_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.mps_tensor.mps_to_unfolded.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.mps_tensor</span></code>.mps_to_unfolded</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.mps_tensor.mps_to_vec.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.mps_tensor</span></code>.mps_to_vec</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.tenalg"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg</span></code>: Tensor algebra</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tenalg.khatri_rao.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg</span></code>.khatri_rao</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tenalg.kronecker.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg</span></code>.kronecker</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tenalg.mode_dot.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg</span></code>.mode_dot</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tenalg.multi_mode_dot.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg</span></code>.multi_mode_dot</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tenalg.proximal.soft_thresholding.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg.proximal</span></code>.soft_thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tenalg.proximal.svd_thresholding.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg.proximal</span></code>.svd_thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tenalg.proximal.procrustes.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg.proximal</span></code>.procrustes</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tenalg.inner.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg</span></code>.inner</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.tenalg.contract.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg</span></code>.contract</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.decomposition"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>: Tensor Decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.decomposition.parafac.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>.parafac</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.decomposition.non_negative_parafac.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>.non_negative_parafac</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.decomposition.sample_khatri_rao.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>.sample_khatri_rao</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.decomposition.randomised_parafac.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>.randomised_parafac</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.decomposition.tucker.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>.tucker</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.decomposition.partial_tucker.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>.partial_tucker</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.decomposition.non_negative_tucker.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>.non_negative_tucker</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.decomposition.robust_pca.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>.robust_pca</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.decomposition.matrix_product_state.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code>.matrix_product_state</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.regression"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.regression</span></code>: Tensor Regression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.regression.tucker_regression.TuckerRegressor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.regression.tucker_regression</span></code>.TuckerRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.regression.kruskal_regression.KruskalRegressor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.regression.kruskal_regression</span></code>.KruskalRegressor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.metrics</span></code>: Performance measures</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.metrics.regression.MSE.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.metrics.regression</span></code>.MSE</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.metrics.regression.RMSE.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.metrics.regression</span></code>.RMSE</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.random"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.random</span></code>: Sampling random tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.random.random_kruskal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.random</span></code>.random_kruskal</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.random.random_tucker.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.random</span></code>.random_tucker</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.random.random_mps.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.random</span></code>.random_mps</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.random.check_random_state.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.random</span></code>.check_random_state</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.datasets</span></code>: Creating and loading data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.datasets.synthetic.gen_image.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.datasets.synthetic</span></code>.gen_image</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-tensorly.contrib"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.contrib</span></code>: Experimental features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/tensorly.contrib.decomposition.matrix_product_state_cross.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.contrib.decomposition</span></code>.matrix_product_state_cross</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sparse-tensor-operations">Sparse tensor operations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Gallery of examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../development_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/JeanKossaifi/tensorly-notebooks">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">People</a></li>
</ul>

                    
                    
                    </div>
                    
                </div>
            </div>

            
            <div class="column is-three-quarters main-column">
                <div class="content main-content">

                    

  <div class="section" id="api-reference">
<h1>API reference</h1>
<div class="section" id="tensorly-manipulating-the-backend-with-a-unified-interface">
<h2><a class="reference internal" href="#module-tensorly" title="tensorly"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly</span></code></a>: Manipulating the backend with a unified interface</h2>
<p>For each backend, tensorly provides the following uniform functions:</p>
<span class="target" id="module-tensorly"></span><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.set_backend.html#tensorly.set_backend" title="tensorly.set_backend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_backend</span></code></a>(backend[, local_threadsafe])</p></td>
<td><p>Changes the backend to the specified one</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.get_backend.html#tensorly.get_backend" title="tensorly.get_backend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_backend</span></code></a>()</p></td>
<td><p>Returns the name of the current backend</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.context.html#tensorly.context" title="tensorly.context"><code class="xref py py-obj docutils literal notranslate"><span class="pre">context</span></code></a>(tensor)</p></td>
<td><p>Returns the context of a tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.tensor.html#tensorly.tensor" title="tensorly.tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor</span></code></a>(data, **context)</p></td>
<td><p>Tensor class</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.is_tensor.html#tensorly.is_tensor" title="tensorly.is_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_tensor</span></code></a>(obj)</p></td>
<td><p>Returns if <cite>obj</cite> is a tensor for the current backend</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.shape.html#tensorly.shape" title="tensorly.shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">shape</span></code></a>(tensor)</p></td>
<td><p>Return the shape of a tensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.ndim.html#tensorly.ndim" title="tensorly.ndim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ndim</span></code></a>(tensor)</p></td>
<td><p>Return the number of dimensions of a tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.to_numpy.html#tensorly.to_numpy" title="tensorly.to_numpy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_numpy</span></code></a>(tensor)</p></td>
<td><p>Returns a copy of the tensor as a NumPy array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.copy.html#tensorly.copy" title="tensorly.copy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">copy</span></code></a>(tensor)</p></td>
<td><p>Return a copy of the given tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.concatenate.html#tensorly.concatenate" title="tensorly.concatenate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">concatenate</span></code></a>(tensors[, axis])</p></td>
<td><p>Concatenate tensors along an axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.reshape.html#tensorly.reshape" title="tensorly.reshape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reshape</span></code></a>(tensor, newshape)</p></td>
<td><p>Gives a new shape to a tensor without changing its data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.transpose.html#tensorly.transpose" title="tensorly.transpose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transpose</span></code></a>(tensor)</p></td>
<td><p>Permute the dimensions of a tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.moveaxis.html#tensorly.moveaxis" title="tensorly.moveaxis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">moveaxis</span></code></a>(tensor, source, destination)</p></td>
<td><p>Move axes of a tensor to new positions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.arange.html#tensorly.arange" title="tensorly.arange"><code class="xref py py-obj docutils literal notranslate"><span class="pre">arange</span></code></a>([start, stop, step])</p></td>
<td><p>Return evenly spaced values within a given interval.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.ones.html#tensorly.ones" title="tensorly.ones"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ones</span></code></a>(shape[, dtype])</p></td>
<td><p>Return a new tensor of given shape and type, filled with ones.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.zeros.html#tensorly.zeros" title="tensorly.zeros"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zeros</span></code></a>(shape[, dtype])</p></td>
<td><p>Return a new tensor of given shape and type, filled with zeros.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.zeros_like.html#tensorly.zeros_like" title="tensorly.zeros_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zeros_like</span></code></a>(tensor)</p></td>
<td><p>Return at tensor of zeros with the same shape and type as a given tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.eye.html#tensorly.eye" title="tensorly.eye"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eye</span></code></a>(N)</p></td>
<td><p>Return a 2-D tensor with ones on the diagonal and zeros elsewhere.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.where.html#tensorly.where" title="tensorly.where"><code class="xref py py-obj docutils literal notranslate"><span class="pre">where</span></code></a>(condition, x, y)</p></td>
<td><p>Return elements, either from <cite>x</cite> or <cite>y</cite>, depending on <cite>condition</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.clip.html#tensorly.clip" title="tensorly.clip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip</span></code></a>(tensor[, a_min, a_max])</p></td>
<td><p>Clip the values of a tensor to within an interval.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.max.html#tensorly.max" title="tensorly.max"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max</span></code></a>(tensor)</p></td>
<td><p>The max value in a tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.min.html#tensorly.min" title="tensorly.min"><code class="xref py py-obj docutils literal notranslate"><span class="pre">min</span></code></a>(tensor)</p></td>
<td><p>The min value in a tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.all.html#tensorly.all" title="tensorly.all"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all</span></code></a>(tensor)</p></td>
<td><p>Returns if all array elements in a tensor are True.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.mean.html#tensorly.mean" title="tensorly.mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mean</span></code></a>(tensor[, axis])</p></td>
<td><p>Compute the mean of a tensor, optionally along an axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.sum.html#tensorly.sum" title="tensorly.sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sum</span></code></a>(tensor[, axis])</p></td>
<td><p>Compute the sum of a tensor, optionally along an axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.prod.html#tensorly.prod" title="tensorly.prod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prod</span></code></a>(tensor[, axis])</p></td>
<td><p>Compute the product of a tensor, optionally along an axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.sign.html#tensorly.sign" title="tensorly.sign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sign</span></code></a>(tensor)</p></td>
<td><p>Computes the element-wise sign of the given input tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.abs.html#tensorly.abs" title="tensorly.abs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">abs</span></code></a>(tensor)</p></td>
<td><p>Computes the element-wise absolute value of the given input tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.sqrt.html#tensorly.sqrt" title="tensorly.sqrt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sqrt</span></code></a>(tensor)</p></td>
<td><p>Computes the element-wise sqrt of the given input tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.norm.html#tensorly.norm" title="tensorly.norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">norm</span></code></a>(tensor[, order, axis])</p></td>
<td><p>Computes the l-<cite>order</cite> norm of a tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.dot.html#tensorly.dot" title="tensorly.dot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dot</span></code></a>(a, b)</p></td>
<td><p>Dot product of two tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.kron.html#tensorly.kron" title="tensorly.kron"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kron</span></code></a>(a, b)</p></td>
<td><p>Kronecker product of two tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.solve.html#tensorly.solve" title="tensorly.solve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">solve</span></code></a>(a, b)</p></td>
<td><p>Solve a linear matrix equation, or system of linear scalar equations.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.qr.html#tensorly.qr" title="tensorly.qr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">qr</span></code></a>(a)</p></td>
<td><p>Compute the qr factorization of a matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.kr.html#tensorly.kr" title="tensorly.kr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kr</span></code></a>(matrices[, weights, mask])</p></td>
<td><p>Khatri-Rao product of a list of matrices</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.partial_svd.html#tensorly.partial_svd" title="tensorly.partial_svd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_svd</span></code></a>(matrix[, n_eigenvecs])</p></td>
<td><p>Computes a fast partial SVD on <cite>matrix</cite></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.base">
<span id="tensorly-base-core-tensor-functions"></span><h2><a class="reference internal" href="#module-tensorly.base" title="tensorly.base"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.base</span></code></a>: Core tensor functions</h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.base.unfold.html#tensorly.base.unfold" title="tensorly.base.unfold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unfold</span></code></a>(tensor, mode)</p></td>
<td><p>Returns the mode-<cite>mode</cite> unfolding of <cite>tensor</cite> with modes starting at <cite>0</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.base.fold.html#tensorly.base.fold" title="tensorly.base.fold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fold</span></code></a>(unfolded_tensor, mode, shape)</p></td>
<td><p>Refolds the mode-<cite>mode</cite> unfolding into a tensor of shape <cite>shape</cite></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.base.tensor_to_vec.html#tensorly.base.tensor_to_vec" title="tensorly.base.tensor_to_vec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor_to_vec</span></code></a>(tensor)</p></td>
<td><p>Vectorises a tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.base.vec_to_tensor.html#tensorly.base.vec_to_tensor" title="tensorly.base.vec_to_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vec_to_tensor</span></code></a>(vec, shape)</p></td>
<td><p>Folds a vectorised tensor back into a tensor of shape <cite>shape</cite></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.base.partial_unfold.html#tensorly.base.partial_unfold" title="tensorly.base.partial_unfold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_unfold</span></code></a>(tensor[, mode, skip_begin, …])</p></td>
<td><p>Partially unfolds a tensor while ignoring the specified number of dimensions at the beginning and the end.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.base.partial_fold.html#tensorly.base.partial_fold" title="tensorly.base.partial_fold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_fold</span></code></a>(unfolded, mode, shape[, …])</p></td>
<td><p>Re-folds a partially unfolded tensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.base.partial_tensor_to_vec.html#tensorly.base.partial_tensor_to_vec" title="tensorly.base.partial_tensor_to_vec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_tensor_to_vec</span></code></a>(tensor[, skip_begin, …])</p></td>
<td><p>Partially vectorises a tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.base.partial_vec_to_tensor.html#tensorly.base.partial_vec_to_tensor" title="tensorly.base.partial_vec_to_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_vec_to_tensor</span></code></a>(matrix, shape[, …])</p></td>
<td><p>Refolds a partially vectorised tensor into a full one</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.kruskal_tensor">
<span id="tensorly-kruskal-tensor-tensors-in-the-kruskal-format"></span><h2><a class="reference internal" href="#module-tensorly.kruskal_tensor" title="tensorly.kruskal_tensor"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.kruskal_tensor</span></code></a>: Tensors in the Kruskal format</h2>
<p>Core operations on Kruskal tensors.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.kruskal_tensor.kruskal_to_tensor.html#tensorly.kruskal_tensor.kruskal_to_tensor" title="tensorly.kruskal_tensor.kruskal_to_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kruskal_to_tensor</span></code></a>(kruskal_tensor)</p></td>
<td><p>Turns the Khatri-product of matrices into a full tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.kruskal_tensor.kruskal_to_unfolded.html#tensorly.kruskal_tensor.kruskal_to_unfolded" title="tensorly.kruskal_tensor.kruskal_to_unfolded"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kruskal_to_unfolded</span></code></a>(kruskal_tensor, mode)</p></td>
<td><p>Turns the khatri-product of matrices into an unfolded tensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.kruskal_tensor.kruskal_to_vec.html#tensorly.kruskal_tensor.kruskal_to_vec" title="tensorly.kruskal_tensor.kruskal_to_vec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kruskal_to_vec</span></code></a>(kruskal_tensor)</p></td>
<td><p>Turns the khatri-product of matrices into a vector</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.kruskal_tensor.kruskal_mode_dot.html#tensorly.kruskal_tensor.kruskal_mode_dot" title="tensorly.kruskal_tensor.kruskal_mode_dot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kruskal_mode_dot</span></code></a>(kruskal_tensor, …[, …])</p></td>
<td><p>n-mode product of a Kruskal tensor and a matrix or vector at the specified mode</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.kruskal_tensor.unfolding_dot_khatri_rao.html#tensorly.kruskal_tensor.unfolding_dot_khatri_rao" title="tensorly.kruskal_tensor.unfolding_dot_khatri_rao"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unfolding_dot_khatri_rao</span></code></a>(tensor, …)</p></td>
<td><p>mode-n unfolding times khatri-rao product of factors</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.tucker_tensor">
<span id="tensorly-tucker-tensor-tensors-in-tucker-format"></span><h2><a class="reference internal" href="#module-tensorly.tucker_tensor" title="tensorly.tucker_tensor"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tucker_tensor</span></code></a>: Tensors in Tucker format</h2>
<p>Core operations on Tucker tensors.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.tucker_tensor.tucker_to_tensor.html#tensorly.tucker_tensor.tucker_to_tensor" title="tensorly.tucker_tensor.tucker_to_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tucker_to_tensor</span></code></a>(tucker_tensor[, …])</p></td>
<td><p>Converts the Tucker tensor into a full tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.tucker_tensor.tucker_to_unfolded.html#tensorly.tucker_tensor.tucker_to_unfolded" title="tensorly.tucker_tensor.tucker_to_unfolded"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tucker_to_unfolded</span></code></a>(tucker_tensor[, mode, …])</p></td>
<td><p>Converts the Tucker decomposition into an unfolded tensor (i.e.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.tucker_tensor.tucker_to_vec.html#tensorly.tucker_tensor.tucker_to_vec" title="tensorly.tucker_tensor.tucker_to_vec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tucker_to_vec</span></code></a>(tucker_tensor[, skip_factor, …])</p></td>
<td><p>Converts a Tucker decomposition into a vectorised tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.tucker_tensor.tucker_mode_dot.html#tensorly.tucker_tensor.tucker_mode_dot" title="tensorly.tucker_tensor.tucker_mode_dot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tucker_mode_dot</span></code></a>(tucker_tensor, …[, …])</p></td>
<td><p>n-mode product of a Tucker tensor and a matrix or vector at the specified mode</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.mps_tensor">
<span id="tensorly-mps-tensor-tensors-in-matrix-product-state-format"></span><h2><a class="reference internal" href="#module-tensorly.mps_tensor" title="tensorly.mps_tensor"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.mps_tensor</span></code></a>: Tensors in Matrix-Product-State format</h2>
<p>Core operations on tensors in Matrix Product State (MPS) format, also known as Tensor-Train (TT)</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.mps_tensor.mps_to_tensor.html#tensorly.mps_tensor.mps_to_tensor" title="tensorly.mps_tensor.mps_to_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mps_to_tensor</span></code></a>(factors)</p></td>
<td><p>Returns the full tensor whose MPS decomposition is given by ‘factors’</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.mps_tensor.mps_to_unfolded.html#tensorly.mps_tensor.mps_to_unfolded" title="tensorly.mps_tensor.mps_to_unfolded"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mps_to_unfolded</span></code></a>(factors, mode)</p></td>
<td><p>Returns the unfolding matrix of a tensor given in MPS (or Tensor-Train) format</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.mps_tensor.mps_to_vec.html#tensorly.mps_tensor.mps_to_vec" title="tensorly.mps_tensor.mps_to_vec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mps_to_vec</span></code></a>(factors)</p></td>
<td><p>Returns the tensor defined by its MPS format (‘factors’) into</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.tenalg">
<span id="tensorly-tenalg-tensor-algebra"></span><h2><a class="reference internal" href="#module-tensorly.tenalg" title="tensorly.tenalg"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg</span></code></a>: Tensor algebra</h2>
<p>The <a class="reference internal" href="#module-tensorly.tenalg" title="tensorly.tenalg"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.tenalg</span></code></a> module contains utilities for Tensor Algebra 
operations such as khatri-rao or kronecker product, n-mode product, etc.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.tenalg.khatri_rao.html#tensorly.tenalg.khatri_rao" title="tensorly.tenalg.khatri_rao"><code class="xref py py-obj docutils literal notranslate"><span class="pre">khatri_rao</span></code></a>(matrices[, weights, skip_matrix, …])</p></td>
<td><p>Khatri-Rao product of a list of matrices</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.tenalg.kronecker.html#tensorly.tenalg.kronecker" title="tensorly.tenalg.kronecker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kronecker</span></code></a>(matrices[, skip_matrix, reverse])</p></td>
<td><p>Kronecker product of a list of matrices</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.tenalg.mode_dot.html#tensorly.tenalg.mode_dot" title="tensorly.tenalg.mode_dot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mode_dot</span></code></a>(tensor, matrix_or_vector, mode)</p></td>
<td><p>n-mode product of a tensor and a matrix or vector at the specified mode</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.tenalg.multi_mode_dot.html#tensorly.tenalg.multi_mode_dot" title="tensorly.tenalg.multi_mode_dot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">multi_mode_dot</span></code></a>(tensor, matrix_or_vec_list[, …])</p></td>
<td><p>n-mode product of a tensor and several matrices or vectors over several modes</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.tenalg.proximal.soft_thresholding.html#tensorly.tenalg.proximal.soft_thresholding" title="tensorly.tenalg.proximal.soft_thresholding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">proximal.soft_thresholding</span></code></a>(tensor, threshold)</p></td>
<td><p>Soft-thresholding operator</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.tenalg.proximal.svd_thresholding.html#tensorly.tenalg.proximal.svd_thresholding" title="tensorly.tenalg.proximal.svd_thresholding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">proximal.svd_thresholding</span></code></a>(matrix, threshold)</p></td>
<td><p>Singular value thresholding operator</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.tenalg.proximal.procrustes.html#tensorly.tenalg.proximal.procrustes" title="tensorly.tenalg.proximal.procrustes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">proximal.procrustes</span></code></a>(matrix)</p></td>
<td><p>Procrustes operator</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.tenalg.inner.html#tensorly.tenalg.inner" title="tensorly.tenalg.inner"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inner</span></code></a>(tensor1, tensor2[, n_modes])</p></td>
<td><p>Generalised inner products between tensors</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.tenalg.contract.html#tensorly.tenalg.contract" title="tensorly.tenalg.contract"><code class="xref py py-obj docutils literal notranslate"><span class="pre">contract</span></code></a>(tensor1, modes1, tensor2, modes2)</p></td>
<td><p>Tensor contraction between two tensors on specified modes</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.decomposition">
<span id="tensorly-decomposition-tensor-decomposition"></span><h2><a class="reference internal" href="#module-tensorly.decomposition" title="tensorly.decomposition"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code></a>: Tensor Decomposition</h2>
<p>The <a class="reference internal" href="#module-tensorly.decomposition" title="tensorly.decomposition"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.decomposition</span></code></a> module includes utilities for performing
tensor decomposition such as CANDECOMP-PARAFAC and Tucker.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.decomposition.parafac.html#tensorly.decomposition.parafac" title="tensorly.decomposition.parafac"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parafac</span></code></a>(tensor, rank[, n_iter_max, init, …])</p></td>
<td><p>CANDECOMP/PARAFAC decomposition via alternating least squares (ALS) Computes a rank-<cite>rank</cite> decomposition of <cite>tensor</cite> <span id="id1">[R3]</span> such that,</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.decomposition.non_negative_parafac.html#tensorly.decomposition.non_negative_parafac" title="tensorly.decomposition.non_negative_parafac"><code class="xref py py-obj docutils literal notranslate"><span class="pre">non_negative_parafac</span></code></a>(tensor, rank[, …])</p></td>
<td><p>Non-negative CP decomposition</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.decomposition.sample_khatri_rao.html#tensorly.decomposition.sample_khatri_rao" title="tensorly.decomposition.sample_khatri_rao"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample_khatri_rao</span></code></a>(matrices, n_samples[, …])</p></td>
<td><p>Random subsample of the Khatri-Rao product of the given list of matrices</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.decomposition.randomised_parafac.html#tensorly.decomposition.randomised_parafac" title="tensorly.decomposition.randomised_parafac"><code class="xref py py-obj docutils literal notranslate"><span class="pre">randomised_parafac</span></code></a>(tensor, rank, n_samples)</p></td>
<td><p>Randomised CP decomposition via sampled ALS</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.decomposition.tucker.html#tensorly.decomposition.tucker" title="tensorly.decomposition.tucker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tucker</span></code></a>(tensor[, rank, ranks, n_iter_max, …])</p></td>
<td><p>Tucker decomposition via Higher Order Orthogonal Iteration (HOI)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.decomposition.partial_tucker.html#tensorly.decomposition.partial_tucker" title="tensorly.decomposition.partial_tucker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_tucker</span></code></a>(tensor, modes[, rank, …])</p></td>
<td><p>Partial tucker decomposition via Higher Order Orthogonal Iteration (HOI)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.decomposition.non_negative_tucker.html#tensorly.decomposition.non_negative_tucker" title="tensorly.decomposition.non_negative_tucker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">non_negative_tucker</span></code></a>(tensor, rank[, …])</p></td>
<td><p>Non-negative Tucker decomposition</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.decomposition.robust_pca.html#tensorly.decomposition.robust_pca" title="tensorly.decomposition.robust_pca"><code class="xref py py-obj docutils literal notranslate"><span class="pre">robust_pca</span></code></a>(X[, mask, tol, reg_E, reg_J, …])</p></td>
<td><p>Robust Tensor PCA via ALM with support for missing values</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.decomposition.matrix_product_state.html#tensorly.decomposition.matrix_product_state" title="tensorly.decomposition.matrix_product_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">matrix_product_state</span></code></a>(input_tensor, rank[, …])</p></td>
<td><p>MPS decomposition via recursive SVD</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.regression">
<span id="tensorly-regression-tensor-regression"></span><h2><a class="reference internal" href="#module-tensorly.regression" title="tensorly.regression"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.regression</span></code></a>: Tensor Regression</h2>
<p>The <a class="reference internal" href="#module-tensorly.regression" title="tensorly.regression"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.regression</span></code></a> module includes classes for performing Tensor
Regression.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.regression.tucker_regression.TuckerRegressor.html#tensorly.regression.tucker_regression.TuckerRegressor" title="tensorly.regression.tucker_regression.TuckerRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tucker_regression.TuckerRegressor</span></code></a>(weight_ranks)</p></td>
<td><p>Tucker tensor regression</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.regression.kruskal_regression.KruskalRegressor.html#tensorly.regression.kruskal_regression.KruskalRegressor" title="tensorly.regression.kruskal_regression.KruskalRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kruskal_regression.KruskalRegressor</span></code></a>(weight_rank)</p></td>
<td><p>Kruskal tensor regression</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.metrics">
<span id="tensorly-metrics-performance-measures"></span><h2><a class="reference internal" href="#module-tensorly.metrics" title="tensorly.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.metrics</span></code></a>: Performance measures</h2>
<p>The <a class="reference internal" href="#module-tensorly.metrics" title="tensorly.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.metrics</span></code></a> module includes utilities to measure performance
(e.g. regression error).</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.metrics.regression.MSE.html#tensorly.metrics.regression.MSE" title="tensorly.metrics.regression.MSE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">regression.MSE</span></code></a>(y_true, y_pred[, axis])</p></td>
<td><p>Returns the mean squared error between the two predictions</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.metrics.regression.RMSE.html#tensorly.metrics.regression.RMSE" title="tensorly.metrics.regression.RMSE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">regression.RMSE</span></code></a>(y_true, y_pred[, axis])</p></td>
<td><p>Returns the regularised mean squared error between the two predictions (the square-root is applied to the mean_squared_error)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.random">
<span id="tensorly-random-sampling-random-tensors"></span><h2><a class="reference internal" href="#module-tensorly.random" title="tensorly.random"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.random</span></code></a>: Sampling random tensors</h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.random.random_kruskal.html#tensorly.random.random_kruskal" title="tensorly.random.random_kruskal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">random_kruskal</span></code></a>(shape, rank[, full, …])</p></td>
<td><p>Generates a random CP tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.random.random_tucker.html#tensorly.random.random_tucker" title="tensorly.random.random_tucker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">random_tucker</span></code></a>(shape, rank[, full, …])</p></td>
<td><p>Generates a random Tucker tensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.random.random_mps.html#tensorly.random.random_mps" title="tensorly.random.random_mps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">random_mps</span></code></a>(shape, rank[, full, random_state])</p></td>
<td><p>Generates a random MPS/ttrain tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.random.check_random_state.html#tensorly.random.check_random_state" title="tensorly.random.check_random_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">check_random_state</span></code></a>(seed)</p></td>
<td><p>Returns a valid RandomState</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.datasets">
<span id="tensorly-datasets-creating-and-loading-data"></span><h2><a class="reference internal" href="#module-tensorly.datasets" title="tensorly.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.datasets</span></code></a>: Creating and loading data</h2>
<p>The <a class="reference internal" href="#module-tensorly.datasets" title="tensorly.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.datasets</span></code></a> module includes utilities to load datasets and
create synthetic data, e.g. for testing purposes.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.datasets.synthetic.gen_image.html#tensorly.datasets.synthetic.gen_image" title="tensorly.datasets.synthetic.gen_image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">synthetic.gen_image</span></code></a>([region, image_height, …])</p></td>
<td><p>Generates an image for regression testing</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-tensorly.contrib">
<span id="tensorly-contrib-experimental-features"></span><h2><a class="reference internal" href="#module-tensorly.contrib" title="tensorly.contrib"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tensorly.contrib</span></code></a>: Experimental features</h2>
<p>A module for experimental functions</p>
<p>Allows to add quickly and test new functions for which the API is not necessarily fixed</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.contrib.decomposition.matrix_product_state_cross.html#tensorly.contrib.decomposition.matrix_product_state_cross" title="tensorly.contrib.decomposition.matrix_product_state_cross"><code class="xref py py-obj docutils literal notranslate"><span class="pre">decomposition.matrix_product_state_cross</span></code></a>(…)</p></td>
<td><p>MPS (tensor-train) decomposition via cross-approximation (TTcross) [1]</p></td>
</tr>
</tbody>
</table>
<div class="section" id="sparse-tensor-operations">
<h3>Sparse tensor operations</h3>
<p>Enables tensor operations on sparse tensors.
Currently, the following decomposition methods are supported (for the NumPy backend, using Sparse):</p>
<span class="target" id="module-tensorly.contrib.sparse"></span><dl class="function">
<dt id="tensorly.contrib.sparse.abs">
<code class="sig-name descname">abs</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Computes the element-wise absolute value of the given input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> : tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.all">
<code class="sig-name descname">all</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Returns if all array elements in a tensor are True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.arange">
<code class="sig-name descname">arange</code><span class="sig-paren">(</span><em class="sig-param">start=0</em>, <em class="sig-param">stop=None</em>, <em class="sig-param">step=None</em><span class="sig-paren">)</span></dt>
<dd><p>Return evenly spaced values within a given interval.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>start</strong> : number, optional</p>
<blockquote>
<div><p>Start of the interval, inclusive. Default is 0.</p>
</div></blockquote>
<p><strong>stop</strong> : number</p>
<blockquote>
<div><p>End of the interval, exclusive.</p>
</div></blockquote>
<p><strong>step</strong> : number, optional</p>
<blockquote>
<div><p>Spacing between values. Default is 1.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.argmax">
<code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param">a</em>, <em class="sig-param">axis=None</em>, <em class="sig-param">out=None</em><span class="sig-paren">)</span></dt>
<dd><p>Returns the indices of the maximum values along an axis.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>a</strong> : array_like</p>
<blockquote>
<div><p>Input array.</p>
</div></blockquote>
<p><strong>axis</strong> : int, optional</p>
<blockquote>
<div><p>By default, the index is into the flattened array, otherwise
along the specified axis.</p>
</div></blockquote>
<p><strong>out</strong> : array, optional</p>
<blockquote>
<div><p>If provided, the result will be inserted into this array. It should
be of the appropriate shape and dtype.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>index_array</strong> : ndarray of ints</p>
<blockquote>
<div><p>Array of indices into the array. It has the same shape as <cite>a.shape</cite>
with the dimension along <cite>axis</cite> removed.</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">ndarray.argmax</span></code>, <a class="reference internal" href="#tensorly.contrib.sparse.argmin" title="tensorly.contrib.sparse.argmin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">argmin</span></code></a></p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">amax</span></code></dt><dd><p>The maximum value along a given axis.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">unravel_index</span></code></dt><dd><p>Convert a flat index into an index tuple.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>In case of multiple occurrences of the maximum values, the indices
corresponding to the first occurrence are returned.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([[10, 11, 12],</span>
<span class="go">       [13, 14, 15]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">array([1, 1, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([2, 2])</span>
</pre></div>
</div>
<p>Indexes of the maximal elements of a N-dimensional array:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ind</span>
<span class="go">(1, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
<span class="go">15</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">array([0, 5, 2, 3, 4, 5])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>  <span class="c1"># Only the first occurrence is returned.</span>
<span class="go">1</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.argmin">
<code class="sig-name descname">argmin</code><span class="sig-paren">(</span><em class="sig-param">a</em>, <em class="sig-param">axis=None</em>, <em class="sig-param">out=None</em><span class="sig-paren">)</span></dt>
<dd><p>Returns the indices of the minimum values along an axis.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>a</strong> : array_like</p>
<blockquote>
<div><p>Input array.</p>
</div></blockquote>
<p><strong>axis</strong> : int, optional</p>
<blockquote>
<div><p>By default, the index is into the flattened array, otherwise
along the specified axis.</p>
</div></blockquote>
<p><strong>out</strong> : array, optional</p>
<blockquote>
<div><p>If provided, the result will be inserted into this array. It should
be of the appropriate shape and dtype.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>index_array</strong> : ndarray of ints</p>
<blockquote>
<div><p>Array of indices into the array. It has the same shape as <cite>a.shape</cite>
with the dimension along <cite>axis</cite> removed.</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">ndarray.argmin</span></code>, <a class="reference internal" href="#tensorly.contrib.sparse.argmax" title="tensorly.contrib.sparse.argmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">argmax</span></code></a></p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">amin</span></code></dt><dd><p>The minimum value along a given axis.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">unravel_index</span></code></dt><dd><p>Convert a flat index into an index tuple.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>In case of multiple occurrences of the minimum values, the indices
corresponding to the first occurrence are returned.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([[10, 11, 12],</span>
<span class="go">       [13, 14, 15]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">array([0, 0, 0])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([0, 0])</span>
</pre></div>
</div>
<p>Indices of the minimum elements of a N-dimensional array:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ind</span>
<span class="go">(0, 0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
<span class="go">10</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span> <span class="o">+</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>
<span class="go">array([10, 11, 12, 13, 10, 15])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>  <span class="c1"># Only the first occurrence is returned.</span>
<span class="go">0</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.clip">
<code class="sig-name descname">clip</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">a_min=None</em>, <em class="sig-param">a_max=None</em><span class="sig-paren">)</span></dt>
<dd><p>Clip the values of a tensor to within an interval.</p>
<p>Given an interval, values outside the interval are clipped to the interval
edges.  For example, if an interval of <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code> is specified, values
smaller than 0 become 0, and values larger than 1 become 1.</p>
<p>Not more than one of <cite>a_min</cite> and <cite>a_max</cite> may be <cite>None</cite>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tl.tensor</p>
<blockquote>
<div><p>The tensor.</p>
</div></blockquote>
<p><strong>a_min</strong> : scalar, optional</p>
<blockquote>
<div><p>Minimum value. If <cite>None</cite>, clipping is not performed on lower bound.</p>
</div></blockquote>
<p><strong>a_max</strong> : scalar, optional</p>
<blockquote>
<div><p>Maximum value. If <cite>None</cite>, clipping is not performed on upper bound.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.concatenate">
<code class="sig-name descname">concatenate</code><span class="sig-paren">(</span><em class="sig-param">tensors</em>, <em class="sig-param">axis=0</em><span class="sig-paren">)</span></dt>
<dd><p>Concatenate tensors along an axis.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensors</strong> : list of tensor</p>
<blockquote>
<div><p>The tensors to concatenate. Non-empty tensors provided must have the
same shape, except along the specified axis.</p>
</div></blockquote>
<p><strong>axis</strong> : int, optional</p>
<blockquote>
<div><p>The axis to concatenate on. Default is 0.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.context">
<code class="sig-name descname">context</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Returns the context of a tensor</p>
<p>Creates a dictionary of the parameters characterising the tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensorly.tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>context</strong> : dict</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tl</span><span class="o">.</span><span class="n">set_backend</span><span class="p">(</span><span class="s1">&#39;numpy&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Imagine you have an existing tensor <cite>tensor</cite>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>The context, here, will simply be the dtype:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tl</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
<span class="go">{&#39;dtype&#39;: dtype(&#39;float32&#39;)}</span>
</pre></div>
</div>
<p>Note that, if you were using, say, PyTorch, the context would also
include the device (i.e. CPU or GPU) and device ID.</p>
<p>If you want to create a new tensor in the same context, use this context:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">new_tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="o">**</span><span class="n">tl</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">tensor</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.copy">
<code class="sig-name descname">copy</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Return a copy of the given tensor</p>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.dot">
<code class="sig-name descname">dot</code><span class="sig-paren">(</span><em class="sig-param">a</em>, <em class="sig-param">b</em><span class="sig-paren">)</span></dt>
<dd><p>Dot product of two tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>a, b</strong> : tensor</p>
<blockquote>
<div><p>The tensors to compute the dot product of.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.eye">
<code class="sig-name descname">eye</code><span class="sig-paren">(</span><em class="sig-param">N</em><span class="sig-paren">)</span></dt>
<dd><p>Return a 2-D tensor with ones on the diagonal and zeros elsewhere.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>N</strong> : int</p>
<blockquote>
<div><p>Number of rows in the output.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.get_backend">
<code class="sig-name descname">get_backend</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorly/backend.html#get_backend"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the name of the current backend</p>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.is_tensor">
<code class="sig-name descname">is_tensor</code><span class="sig-paren">(</span><em class="sig-param">obj</em><span class="sig-paren">)</span></dt>
<dd><p>Returns if <cite>obj</cite> is a tensor for the current backend</p>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.kr">
<code class="sig-name descname">kr</code><span class="sig-paren">(</span><em class="sig-param">matrices</em>, <em class="sig-param">weights=None</em>, <em class="sig-param">mask=None</em><span class="sig-paren">)</span></dt>
<dd><p>Khatri-Rao product of a list of matrices</p>
<p>This can be seen as a column-wise kronecker product.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>matrices</strong> : list of tensors</p>
<blockquote>
<div><p>List of 2D tensors with the same number of columns, i.e.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">len</span><span class="p">(</span><span class="n">matrices</span><span class="p">):</span>
    <span class="n">matrices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_i</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>khatri_rao_product</strong> : tensor of shape <code class="docutils literal notranslate"><span class="pre">(prod(n_i),</span> <span class="pre">m)</span></code></p>
<blockquote>
<div><p>Where <code class="docutils literal notranslate"><span class="pre">prod(n_i)</span> <span class="pre">=</span> <span class="pre">prod([m.shape[0]</span> <span class="pre">for</span> <span class="pre">m</span> <span class="pre">in</span> <span class="pre">matrices])</span></code> (i.e. the
product of the number of rows of all the matrices in the product.)</p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Mathematically:</p>
<div class="math">
<p><img src="../_images/math/881588c7e264617a22ab13ee01a8a7124b0ac018.png" alt="\text{If every matrix } U_k \text{ is of size } (I_k \times R),\\
\text{Then } \left(U_1 \bigodot \cdots \bigodot U_n \right) \\
text{ is of size } (\prod_{k=1}^n I_k \times R)"/></p>
</div></dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.kron">
<code class="sig-name descname">kron</code><span class="sig-paren">(</span><em class="sig-param">a</em>, <em class="sig-param">b</em><span class="sig-paren">)</span></dt>
<dd><p>Kronecker product of two tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>a, b</strong> : tensor</p>
<blockquote>
<div><p>The tensors to compute the kronecker product of.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.max">
<code class="sig-name descname">max</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>The max value in a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>scalar</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.mean">
<code class="sig-name descname">mean</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">axis=None</em><span class="sig-paren">)</span></dt>
<dd><p>Compute the mean of a tensor, optionally along an axis.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
<p><strong>axis</strong> : int, optional</p>
<blockquote>
<div><p>If provided, the mean is computed along this axis.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> : scalar or tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.min">
<code class="sig-name descname">min</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>The min value in a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>scalar</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.moveaxis">
<code class="sig-name descname">moveaxis</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">source</em>, <em class="sig-param">destination</em><span class="sig-paren">)</span></dt>
<dd><p>Move axes of a tensor to new positions.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tl.tensor</p>
<p><strong>source</strong> : int or sequence of int</p>
<blockquote>
<div><p>Original positions of the axes to move. These must be unique.</p>
</div></blockquote>
<p><strong>destination</strong> : int or sequence of int</p>
<blockquote>
<div><p>Destination positions for each of the original axes. These must also be
unique.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.ndim">
<code class="sig-name descname">ndim</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Return the number of dimensions of a tensor</p>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.norm">
<code class="sig-name descname">norm</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">order=2</em>, <em class="sig-param">axis=None</em><span class="sig-paren">)</span></dt>
<dd><p>Computes the l-<cite>order</cite> norm of a tensor.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tl.tensor</p>
<p><strong>order</strong> : int</p>
<p><strong>axis</strong> : int or tuple</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>float or tensor</p>
<blockquote>
<div><p>If <cite>axis</cite> is provided returns a tensor.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.ones">
<code class="sig-name descname">ones</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span></dt>
<dd><p>Return a new tensor of given shape and type, filled with ones.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shape</strong> : int or sequence of ints</p>
<blockquote>
<div><p>Shape of the new tensor.</p>
</div></blockquote>
<p><strong>dtype</strong> : data-type, optional</p>
<blockquote>
<div><p>The desired data-type for the tensor.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.override_module_dispatch">
<code class="sig-name descname">override_module_dispatch</code><span class="sig-paren">(</span><em class="sig-param">module_name</em>, <em class="sig-param">getter_fun</em>, <em class="sig-param">dir_fun</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorly/backend.html#override_module_dispatch"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Override the module’s dispatch mechanism</p>
<p>In Python &gt;= 3.7, we use module’s __getattr__ and __dir__
On older versions, we override the sys.module[__name__].__class__</p>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.partial_svd">
<code class="sig-name descname">partial_svd</code><span class="sig-paren">(</span><em class="sig-param">matrix</em>, <em class="sig-param">n_eigenvecs=None</em><span class="sig-paren">)</span></dt>
<dd><p>Computes a fast partial SVD on <cite>matrix</cite></p>
<p>If <cite>n_eigenvecs</cite> is specified, sparse eigendecomposition is used on
either matrix.dot(matrix.T) or matrix.T.dot(matrix).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>matrix</strong> : tensor</p>
<blockquote>
<div><p>A 2D tensor.</p>
</div></blockquote>
<p><strong>n_eigenvecs</strong> : int, optional, default is None</p>
<blockquote>
<div><p>If specified, number of eigen[vectors-values] to return.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>U</strong> : 2-D tensor, shape (matrix.shape[0], n_eigenvecs)</p>
<blockquote>
<div><p>Contains the right singular vectors</p>
</div></blockquote>
<p><strong>S</strong> : 1-D tensor, shape (n_eigenvecs, )</p>
<blockquote>
<div><p>Contains the singular values of <cite>matrix</cite></p>
</div></blockquote>
<p><strong>V</strong> : 2-D tensor, shape (n_eigenvecs, matrix.shape[1])</p>
<blockquote>
<div><p>Contains the left singular vectors</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.prod">
<code class="sig-name descname">prod</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">axis=None</em><span class="sig-paren">)</span></dt>
<dd><p>Compute the product of a tensor, optionally along an axis.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
<p><strong>axis</strong> : int, optional</p>
<blockquote>
<div><p>If provided, the product is computed along this axis.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> : scalar or tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.qr">
<code class="sig-name descname">qr</code><span class="sig-paren">(</span><em class="sig-param">a</em><span class="sig-paren">)</span></dt>
<dd><p>Compute the qr factorization of a matrix.</p>
<p>Factor the matrix <cite>a</cite> as <em>qr</em>, where <cite>q</cite> is orthonormal and <cite>r</cite> is
upper-triangular.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>a</strong> : tensor, shape (M, N)</p>
<blockquote>
<div><p>Matrix to be factored.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Q, R</strong> : tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.reshape">
<code class="sig-name descname">reshape</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">newshape</em><span class="sig-paren">)</span></dt>
<dd><p>Gives a new shape to a tensor without changing its data.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tl.tensor</p>
<p><strong>newshape</strong> : int or tuple of ints</p>
<blockquote>
<div><p>The new shape should be compatible with the original shape. If an
integer, then the result will be a 1-D tensor of that length.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.set_backend">
<code class="sig-name descname">set_backend</code><span class="sig-paren">(</span><em class="sig-param">backend</em>, <em class="sig-param">local_threadsafe=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/tensorly/backend.html#set_backend"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Changes the backend to the specified one</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>backend</strong> : tensorly.Backend or str</p>
<blockquote>
<div><p>name of the backend to load or Backend Class</p>
</div></blockquote>
<p><strong>local_threadsafe</strong> : bool, optional, default is False</p>
<blockquote>
<div><p>If False, set the backend as default for all threads</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.shape">
<code class="sig-name descname">shape</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Return the shape of a tensor</p>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.sign">
<code class="sig-name descname">sign</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Computes the element-wise sign of the given input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> : tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param">a</em>, <em class="sig-param">b</em><span class="sig-paren">)</span></dt>
<dd><p>Solve a linear matrix equation, or system of linear scalar equations.</p>
<p>Computes the “exact” solution, <cite>x</cite>, of the well-determined, i.e., full
rank, linear matrix equation <cite>ax = b</cite>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>a</strong> : tensor, shape (M, M)</p>
<blockquote>
<div><p>The coefficient matrix.</p>
</div></blockquote>
<p><strong>b</strong> : tensor, shape (M,) or (M, K)</p>
<blockquote>
<div><p>The ordinate values.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> : tensor, shape (M,) or (M, K)</p>
<blockquote>
<div><p>Solution to the system a x = b. Returned shape is identical to <cite>b</cite>.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.sqrt">
<code class="sig-name descname">sqrt</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Computes the element-wise sqrt of the given input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> : tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.stack">
<code class="sig-name descname">stack</code><span class="sig-paren">(</span><em class="sig-param">arrays</em>, <em class="sig-param">axis=0</em>, <em class="sig-param">out=None</em><span class="sig-paren">)</span></dt>
<dd><p>Join a sequence of arrays along a new axis.</p>
<p>The <cite>axis</cite> parameter specifies the index of the new axis in the dimensions
of the result. For example, if <code class="docutils literal notranslate"><span class="pre">axis=0</span></code> it will be the first dimension
and if <code class="docutils literal notranslate"><span class="pre">axis=-1</span></code> it will be the last dimension.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.10.0.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>arrays</strong> : sequence of array_like</p>
<blockquote>
<div><p>Each array must have the same shape.</p>
</div></blockquote>
<p><strong>axis</strong> : int, optional</p>
<blockquote>
<div><p>The axis in the result array along which the input arrays are stacked.</p>
</div></blockquote>
<p><strong>out</strong> : ndarray, optional</p>
<blockquote>
<div><p>If provided, the destination to place the result. The shape must be
correct, matching that of what stack would have returned if no
out argument were specified.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>stacked</strong> : ndarray</p>
<blockquote>
<div><p>The stacked array has one more dimension than the input arrays.</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#tensorly.contrib.sparse.concatenate" title="tensorly.contrib.sparse.concatenate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">concatenate</span></code></a></dt><dd><p>Join a sequence of arrays along an existing axis.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">split</span></code></dt><dd><p>Split array into a list of multiple sub-arrays of equal size.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">block</span></code></dt><dd><p>Assemble arrays from blocks.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">arrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(10, 3, 4)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(3, 10, 4)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(3, 4, 10)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
<span class="go">array([[1, 2, 3],</span>
<span class="go">       [2, 3, 4]])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[1, 2],</span>
<span class="go">       [2, 3],</span>
<span class="go">       [3, 4]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.sum">
<code class="sig-name descname">sum</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">axis=None</em><span class="sig-paren">)</span></dt>
<dd><p>Compute the sum of a tensor, optionally along an axis.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
<p><strong>axis</strong> : int, optional</p>
<blockquote>
<div><p>If provided, the sum is computed along this axis.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>out</strong> : scalar or tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.tensor">
<code class="sig-name descname">tensor</code><span class="sig-paren">(</span><em class="sig-param">data</em>, <em class="sig-param">**context</em><span class="sig-paren">)</span></dt>
<dd><p>Tensor class</p>
<p>Returns a tensor on the specified context, depending on the backend.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tl</span><span class="o">.</span><span class="n">set_backend</span><span class="p">(</span><span class="s1">&#39;numpy&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tl</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="go">array([1, 2, 3])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.to_numpy">
<code class="sig-name descname">to_numpy</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Returns a copy of the tensor as a NumPy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tl.tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>numpy_tensor</strong> : numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.transpose">
<code class="sig-name descname">transpose</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Permute the dimensions of a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.where">
<code class="sig-name descname">where</code><span class="sig-paren">(</span><em class="sig-param">condition</em>, <em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span></dt>
<dd><p>Return elements, either from <cite>x</cite> or <cite>y</cite>, depending on <cite>condition</cite>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>condition</strong> : tensor</p>
<blockquote>
<div><p>When True, yield element from <cite>x</cite>, otherwise from <cite>y</cite>.</p>
</div></blockquote>
<p><strong>x, y</strong> : tensor</p>
<blockquote>
<div><p>Values from which to choose.</p>
</div></blockquote>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.zeros">
<code class="sig-name descname">zeros</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span></dt>
<dd><p>Return a new tensor of given shape and type, filled with zeros.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shape</strong> : int or sequence of ints</p>
<blockquote>
<div><p>Shape of the new tensor.</p>
</div></blockquote>
<p><strong>dtype</strong> : data-type, optional</p>
<blockquote>
<div><p>The desired data-type for the tensor.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tensorly.contrib.sparse.zeros_like">
<code class="sig-name descname">zeros_like</code><span class="sig-paren">(</span><em class="sig-param">tensor</em><span class="sig-paren">)</span></dt>
<dd><p>Return at tensor of zeros with the same shape and type as a given tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> : tensor</p>
</dd>
</dl>
</dd></dl>

<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.contrib.sparse.decomposition.tucker.html#tensorly.contrib.sparse.decomposition.tucker" title="tensorly.contrib.sparse.decomposition.tucker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse.decomposition.tucker</span></code></a>(tensor[, rank, …])</p></td>
<td><p>Tucker decomposition via Higher Order Orthogonal Iteration (HOI)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.contrib.sparse.decomposition.partial_tucker.html#tensorly.contrib.sparse.decomposition.partial_tucker" title="tensorly.contrib.sparse.decomposition.partial_tucker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse.decomposition.partial_tucker</span></code></a>(tensor, …)</p></td>
<td><p>Partial tucker decomposition via Higher Order Orthogonal Iteration (HOI)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.contrib.sparse.decomposition.non_negative_tucker.html#tensorly.contrib.sparse.decomposition.non_negative_tucker" title="tensorly.contrib.sparse.decomposition.non_negative_tucker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse.decomposition.non_negative_tucker</span></code></a>(…)</p></td>
<td><p>Non-negative Tucker decomposition</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.contrib.sparse.decomposition.robust_pca.html#tensorly.contrib.sparse.decomposition.robust_pca" title="tensorly.contrib.sparse.decomposition.robust_pca"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse.decomposition.robust_pca</span></code></a>(X[, mask, …])</p></td>
<td><p>Robust Tensor PCA via ALM with support for missing values</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensorly.contrib.sparse.decomposition.parafac.html#tensorly.contrib.sparse.decomposition.parafac" title="tensorly.contrib.sparse.decomposition.parafac"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse.decomposition.parafac</span></code></a>(tensor, rank[, …])</p></td>
<td><p>CANDECOMP/PARAFAC decomposition via alternating least squares (ALS) Computes a rank-<cite>rank</cite> decomposition of <cite>tensor</cite> <span id="id2">[R14]</span> such that,</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensorly.contrib.sparse.decomposition.non_negative_parafac.html#tensorly.contrib.sparse.decomposition.non_negative_parafac" title="tensorly.contrib.sparse.decomposition.non_negative_parafac"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse.decomposition.non_negative_parafac</span></code></a>(…)</p></td>
<td><p>Non-negative CP decomposition</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>




                    <nav class="pagination">
    
    
    <a class="button is-medium pagination-previous" href="../user_guide/sparse_backend.html" title="6. Sparse Backend" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span>Previous</span>
    </a>
    
    
    <a class="button is-medium pagination-next" href="generated/tensorly.set_backend.html" title="tensorly.set_backend" accesskey="n">
        <span>Next </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

                </div>

                <footer class="footer">
    <div class="container has-text-centered">

        <p>
                &copy; 2016 - 2019, Jean Kossaifi.
        </p> 
    </div>
</footer>
            </div>

        </div>

        
        

        <script src="../_static/navigation.min.js"></script>
        <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-86209849-1', 'auto');
    ga('send', 'pageview');
</script>

    </body>
</html>