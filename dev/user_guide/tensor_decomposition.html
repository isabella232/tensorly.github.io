


<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">

        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta name="keywords" content="tensor learning, tensor decomposition, tensor operations">
        <meta name="description" content="TensorLy: Tensor learning in Python">

        
        <meta name="author" content="Jean Kossaifi">
        <title>TensorLy: Tensor learning in Python</title>
        

        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="../_static/bulma.min.css" />
        <link rel="stylesheet" type="text/css" href="../_static/base.min.css" />
        <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

        
        

        
        
    </head>

    <body>
        
        <nav class="navbar is-dark has-shadow top" id="top">
    <div class="navbar-brand">
        <a class="navbar-item navbar-title" href="../home.html">
            TensorLy
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="../index.html">
            <i class="fa fa-home" aria-hidden="true"></i>
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
            <span class="icon"><i class="fa fa-github"></i></span>
        </a>

		<span class="navbar-burger" data-target="NavbarMenu" >
			<span></span>
			<span></span>
			<span></span>
		</span>

    </div>

	<div id="NavbarMenu" class="navbar-menu">
		<div class="navbar-start">

			<a class="navbar-item" href="../installation.html">
				Install
			</a>
			<a class="navbar-item" href="index.html">
				User guide
			</a>
			<a class="navbar-item" href="../modules/api.html">
				API
			</a>
			<a class="navbar-item" href="../auto_examples/index.html">
				Examples
			</a>
			<a class="navbar-item" href="../authors.html">
				People
			</a>
			<a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
				Notebooks
			</a>

		</div>

		<div class="navbar-end">
			<a class="navbar-item is-tab tooltip is-hidden-touch" href="../index.html">
				<i class="fa fa-home" aria-hidden="true"></i>
				<span class="tooltiptext">Home page</span>
			</a>

			<a class="navbar-item is-tab tooltip is-hidden-touch" href="https://github.com/tensorly/tensorly" target="_blank">
				<span class="tooltiptext">Open project on Github</span>
				<span class="icon"><i class="fa fa-github"></i></span>
			</a>

		</div>
    </div>
</nav>
 

        
        <div class="columns">
            
            <div class="column is-one-quarter is-hidden-mobile aside">
                <div class="sidebar" id="sidebar">
                    
                    <div class="search">
                        <div class="search-title">
                            Search in TensorLy
                        </div>

                        <script>
                          (function() {
                            var cx = '002285679029256671182:5tfqz3cvmm8';
                            var gcse = document.createElement('script');
                            gcse.type = 'text/javascript';
                            gcse.async = true;
                            gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
                            var s = document.getElementsByTagName('script')[0];
                            s.parentNode.insertBefore(gcse, s);
                          })();
                        </script>
                        <gcse:searchbox-only></gcse:searchbox-only>
                        
                    </div>

                    <div class="toc">
                    
                    
                    
                    
                        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installing tensorly</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="quickstart.html">1. Quick-Start</a></li>
<li class="toctree-l2"><a class="reference internal" href="backend.html">2. TensorLy’s backend system</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_basics.html">3. Tensor basics</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">4. Tensor decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#kruskal-form-of-a-tensor">4.1. Kruskal form of a tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tucker-form-of-a-tensor">4.2. Tucker form of a tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#matrix-product-state-tensor-train-decomposition">4.3. Matrix-Product-State / Tensor-Train Decomposition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#references">4.4. References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tensor_regression.html">5. Tensor regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="sparse_backend.html">6. Sparse Backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="sparse_backend.html#usage">7. Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="sparse_backend.html#example">8. Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Gallery of examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../development_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/JeanKossaifi/tensorly-notebooks">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">People</a></li>
</ul>

                    
                    
                    </div>
                    
                </div>
            </div>

            
            <div class="column is-three-quarters main-column">
                <div class="content main-content">

                    

  <div class="section" id="tensor-decomposition">
<h1><span class="section-number">4. </span>Tensor decomposition</h1>
<p>One of the greatest features of tensors is that they can be represented compactly in decomposed forms and we have powerful methods with guarantees to obtain these decompositions.</p>
<p>In this tutorial we will go over these decomposed forms and how to perform tensor decomposition.
Refer to <a class="footnote-reference" href="#id3" id="id1">[1]</a> for more information on tensor decomposition.</p>
<div class="section" id="kruskal-form-of-a-tensor">
<h2><span class="section-number">4.1. </span>Kruskal form of a tensor</h2>
<p>The idea is to express the tensor as a sum of rank one tensors. That is, a sum of outer product of vectors.
Such representation can be obtained by applying Canonical Polyadic Decomposition (also known as CANDECOMP-PARAFAC, CP, or PARAFAC decomposition).</p>
<div class="section" id="candecomp-parafac-decomposition">
<h3><span class="section-number">4.1.1. </span>CANDECOMP-PARAFAC decomposition</h3>
<p>We demonstrate here how to perform a Canonical Polyadic Decomposition. A rank-r Parafac decomposes a tensor into a linear combination of r rank-1 tensors (See <a class="footnote-reference" href="#id3" id="id2">[1]</a> for more details).</p>
<p>First, let’s create a second order tensor that is zero everywhere except in a swiss shape that is one.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.],</span>
<span class="go">                        [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.],</span>
<span class="go">                        [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.],</span>
<span class="go">                        [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])</span>
</pre></div>
</div>
<p>We will now apply a rank-2 CANDECOMP-PARAFAC (<a class="reference internal" href="../modules/generated/tensorly.decomposition.parafac.html#tensorly.decomposition.parafac" title="tensorly.decomposition.parafac"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.decomposition.parafac</span></code></a>) decomposition on <cite>tensor</cite>
to decompose this into a kruskal tensor.</p>
<p>A Parafac decompositions expresses the tensor as a kruskal tensor that can be represented as a list of factors (matrices).
The <code class="xref py py-func docutils literal notranslate"><span class="pre">parafac</span></code> function therefore returns a list of factors.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">parafac</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">factors</span> <span class="o">=</span> <span class="n">parafac</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">]</span>
<span class="go">[(12, 2), (12, 2)]</span>
</pre></div>
</div>
<p>From this <strong>kruskal tensor</strong> (presented as a list of matrices) you can reconstruct a full tensor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">kruskal_to_tensor</span><span class="p">(</span><span class="n">factors</span><span class="p">))</span>
<span class="go">[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]</span>
<span class="go"> [ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]</span>
<span class="go"> [ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]</span>
<span class="go"> [ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="tucker-form-of-a-tensor">
<h2><span class="section-number">4.2. </span>Tucker form of a tensor</h2>
<p>The Tucker decomposition can be seen as a generalisation of the CP decomposition: it decomposes the tensor into a small core tensor and factor matrices. CP can be seen as a Tucker decomposition with a super-diagonal core.</p>
<p>A tensor in its decomposed Tucker form is therefore nothing more than a core tensor with the same order as the original tensor and a list of projection matrices, one for each mode of the core tensor.</p>
<div class="section" id="tucker-decomposition">
<h3><span class="section-number">4.2.1. </span>Tucker decomposition</h3>
<p>Tucker (classical and non-negative) are available in TensorLy (<a class="reference internal" href="../modules/generated/tensorly.decomposition.tucker.html#tensorly.decomposition.tucker" title="tensorly.decomposition.tucker"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.decomposition.tucker</span></code></a> and <a class="reference internal" href="../modules/generated/tensorly.decomposition.non_negative_tucker.html#tensorly.decomposition.non_negative_tucker" title="tensorly.decomposition.non_negative_tucker"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.decomposition.non_negative_tucker</span></code></a>).</p>
<p>Using the same tensor as previously, we will perform a rank [2, 3]-decomposition of <cite>tensor</cite>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">tucker</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">core</span><span class="p">,</span> <span class="n">factors</span> <span class="o">=</span> <span class="n">tucker</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go"># The core is a smaller tensor of size (2, 3):</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">core</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">]</span>
<span class="go">[(12, 2), (12, 3)]</span>
</pre></div>
</div>
<p>As before, we can reconstruct a full tensor from our Tucker decomposition:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly</span> <span class="kn">import</span> <span class="n">tucker_to_tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">tucker_to_tensor</span><span class="p">(</span><span class="n">core</span><span class="p">,</span> <span class="n">factors</span><span class="p">)</span>
<span class="go">[[  0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [  7.746e-17   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   0.000e+00]</span>
<span class="go"> [  7.746e-17   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   0.000e+00]</span>
<span class="go"> [  7.746e-17   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   0.000e+00]</span>
<span class="go"> [  7.746e-17   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [  0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00]]</span>
</pre></div>
</div>
<p>Note that some coefficients are almost zero (10e-16) but not exactly due to numerical approximations.</p>
</div>
</div>
<div class="section" id="matrix-product-state-tensor-train-decomposition">
<h2><span class="section-number">4.3. </span>Matrix-Product-State / Tensor-Train Decomposition</h2>
<p>The tensor-train decomposition, also known as matrix product state in physics community, is a way of decompositing high order tensors into third order ones. For a order d tensor A[i1,…,id], it splits each dimension into a order 3 sub-tensor, which we called factors or cores. One of the dimension of the sub-tensor is the real physical dimension, while the other two are edges connecting the cores before and after it.</p>
<div class="math">
<p><img src="../_images/math/fcdb4cdf192ddb1386b413b62c576921590180b0.png" alt="A[i_1, \ldots, i_d] \approx \sum_{\alpha_1}\cdots\sum_{\alpha_{d-1}}G_1(i_1, \alpha_1)G_2(\alpha_1, i_2, \alpha_2)G_3(\alpha_2, i_3, \alpha_3)\cdots G_d(\alpha_{d-1},i_d)"/></p>
</div><p>The advantage of the MPS/tensor-train decomposition is that both of its number of entries (storage) and computational time is linear in the number of dimensions, making high dimensional problem more easily addressable.</p>
<div class="section" id="implementations">
<h3><span class="section-number">4.3.1. </span>Implementations</h3>
<p>Two versions tensor train decompositions are available in TensorLy: and SVD-based decomposition method (<code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.decomposition.mps_decomposition</span></code> and a cross approximation-based method <code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.contrib.mps_decomposition_cross</span></code>).</p>
<p>Using the same tensor as previously, we will perform a rank [1,2,1]-decomposition of the shape (12,12) <cite>tensor</cite> meaning the first core has shape (1,12,2) and the second has (2,12,1).:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">matrix_product_state</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">factors</span> <span class="o">=</span> <span class="n">matrix_product_state</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">]</span>
<span class="go">[(1, 12, 2), (2, 12, 1)]</span>
</pre></div>
</div>
<p>As before, we can reconstruct a full tensor from our Tensor-train  decomposition:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">tensorly</span> <span class="kn">import</span> <span class="n">mps_to_tensor</span>
  <span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mps_to_tensor</span><span class="p">(</span><span class="n">factors</span><span class="p">),</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span> <span class="o">-</span><span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span> <span class="o">-</span><span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span> <span class="o">-</span><span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span> <span class="o">-</span><span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Note that for the matrix case, MPS/tensor-train decomposition is equivalent to a the singular value decomposition. This matrix is rank 2, so it can be fully recovered with a rank-2 decomposition.</p>
</div>
</div>
<div class="section" id="references">
<h2><span class="section-number">4.4. </span>References</h2>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id2">2</a>)</em> T.G.Kolda and B.W.Bader, “Tensor Decompositions and Applications”,
SIAM REVIEW, vol. 51, n. 3, pp. 455-500, 2009.</td></tr>
</tbody>
</table>
</div>
</div>




                    <nav class="pagination">
    
    
    <a class="button is-medium pagination-previous" href="tensor_basics.html" title="3. Tensor basics" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span>Previous</span>
    </a>
    
    
    <a class="button is-medium pagination-next" href="tensor_regression.html" title="5. Tensor regression" accesskey="n">
        <span>Next </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

                </div>

                <footer class="footer">
    <div class="container has-text-centered">

        <p>
                &copy; 2016 - 2020, Jean Kossaifi.
        </p> 
    </div>
</footer>
            </div>

        </div>

        
        

        <script src="../_static/navigation.min.js"></script>
        <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-86209849-1', 'auto');
    ga('send', 'pageview');
</script>

    </body>
</html>