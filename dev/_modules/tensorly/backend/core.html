
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tensorly.backend.core &#8212; TensorLy: Tensor Learning in Python</title> 
<link rel="stylesheet" href="../../../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../../../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../../../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../../../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../../../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../../../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/tensorly_style.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/gallery-rendered-html.css" />

  
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
 <script src="../../../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3V91QCZR03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3V91QCZR03');
</script>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="search" title="Search" href="../../../search.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        <!-- Always displayed, last item has to be navbar-burger -->

          <a class="navbar-item" href="../../../index.html">
            <img src="../../../_static/logo_tensorly.png" height="28">
          </a>

          <!-- <a class="navbar-item is-hidden-desktop" href="../../../index.html">
            <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
          </a> -->
          <a class="navbar-item is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        <!-- only on larger displays (> 1024px) -->

          <div class="navbar-start">
          <!-- RIGHT -->
            <a class="navbar-item" href="../../../installation.html">
              Install
            </a>
            <a class="navbar-item" href="../../../user_guide/index.html">
              User Guide
            </a>
            <a class="navbar-item" href="../../../modules/api.html">
              API
            </a>
            <a class="navbar-item" href="../../../auto_examples/index.html">
              Examples
            </a>
            <a class="navbar-item" href="../../../about.html">
              About Us
            </a>
            <a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
              Notebooks
            </a>

          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            <!-- LEFT -->

            <!-- <a class="navbar-item is-hidden-touch" href="../../../index.html">
              <span class="icon-text">
                <span class="icon">
                  <i class="fa fa-home"></i>
                </span>
                <span>Home</span>
              </span>
              <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
            </a> -->
            <a class="button is-hidden-touch is-dark" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
                <!-- <span class="icon"><i class="fab fa-github"></i></span> -->
            </a>

            </div> <!-- navbar item -->
          </div> <!-- navbar end -->
        </div> <!-- only large items -->

      </nav>
      
    </navbar>
  </header>

  <div id="column-container">
  <div class="columns is-mobile is-centered">
      
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    <!-- Side menu  -->
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../../../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search in TensorLy" name="q" aria-labelledby="searchlabel">
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>$('#searchbox').show(0);</script>
</div>
      
      <div class="sidebar-menu-toc">
      <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installing tensorly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide/index.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Gallery of examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../development_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/JeanKossaifi/tensorly-notebooks">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about.html">About us</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

    <div class="column main-column">

      <!-- Main content  -->
      <section class="main-content">

        <!-- Toggle menu button -->
            
        <div class="side-menu-toggle">
          <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
            <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
            <span>menu</span> 
          </button>
        </div>
        

        <div class="content">
          
  <h1>Source code for tensorly.backend.core</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">importlib</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">threading</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.linalg</span>
<span class="kn">import</span> <span class="nn">scipy.sparse.linalg</span>


<span class="k">class</span> <span class="nc">Index</span><span class="p">():</span>
    <span class="vm">__slots__</span> <span class="o">=</span> <span class="p">()</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">indices</span>


<span class="k">class</span> <span class="nc">Backend</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">register_method</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Register a method with the backend.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name : str</span>
<span class="sd">            The method name.</span>
<span class="sd">        func : callable</span>
<span class="sd">            The method</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="nb">staticmethod</span><span class="p">(</span><span class="n">func</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">int64</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">int32</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">float64</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">float32</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">SVD_FUNS</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">context</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the context of a tensor</span>

<span class="sd">        Creates a dictionary of the parameters characterising the tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensorly.tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        context : dict</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import tensorly as tl</span>
<span class="sd">        &gt;&gt;&gt; tl.set_backend(&#39;numpy&#39;)</span>

<span class="sd">        Imagine you have an existing tensor `tensor`:</span>

<span class="sd">        &gt;&gt;&gt; tensor = tl.tensor([0, 1, 2], dtype=tl.float32)</span>

<span class="sd">        The context, here, will simply be the dtype:</span>

<span class="sd">        &gt;&gt;&gt; tl.context(tensor)</span>
<span class="sd">        {&#39;dtype&#39;: dtype(&#39;float32&#39;)}</span>

<span class="sd">        Note that, if you were using, say, PyTorch, the context would also</span>
<span class="sd">        include the device (i.e. CPU or GPU) and device ID.</span>

<span class="sd">        If you want to create a new tensor in the same context, use this context:</span>

<span class="sd">        &gt;&gt;&gt; new_tensor = tl.tensor([1, 2, 3], **tl.context(tensor))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">context</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Tensor class</span>

<span class="sd">        Returns a tensor on the specified context, depending on the backend.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import tensorly as tl</span>
<span class="sd">        &gt;&gt;&gt; tl.set_backend(&#39;numpy&#39;)</span>
<span class="sd">        &gt;&gt;&gt; tl.tensor([1, 2, 3], dtype=tl.int64)</span>
<span class="sd">        array([1, 2, 3])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">is_tensor</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns if `obj` is a tensor for the current backend&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the shape of a tensor&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">ndim</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the number of dimensions of a tensor&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">to_numpy</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a copy of the tensor as a NumPy array.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tl.tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy_tensor : numpy.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a copy of the given tensor&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">concatenate</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Concatenate tensors along an axis.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensors : list of tensor</span>
<span class="sd">            The tensors to concatenate. Non-empty tensors provided must have the</span>
<span class="sd">            same shape, except along the specified axis.</span>
<span class="sd">        axis : int, optional</span>
<span class="sd">            The axis to concatenate on. Default is 0.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">newshape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gives a new shape to a tensor without changing its data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tl.tensor</span>
<span class="sd">        newshape : int or tuple of ints</span>
<span class="sd">            The new shape should be compatible with the original shape. If an</span>
<span class="sd">            integer, then the result will be a 1-D tensor of that length.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Permute the dimensions of a tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return evenly spaced values within a given interval.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        start : number, optional</span>
<span class="sd">            Start of the interval, inclusive. Default is 0.</span>
<span class="sd">        stop : number</span>
<span class="sd">            End of the interval, exclusive.</span>
<span class="sd">        step : number, optional</span>
<span class="sd">            Spacing between values. Default is 1.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a new tensor of given shape and type, filled with ones.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        shape : int or sequence of ints</span>
<span class="sd">            Shape of the new tensor.</span>
<span class="sd">        dtype : data-type, optional</span>
<span class="sd">            The desired data-type for the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a new tensor of given shape and type, filled with zeros.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        shape : int or sequence of ints</span>
<span class="sd">            Shape of the new tensor.</span>
<span class="sd">        dtype : data-type, optional</span>
<span class="sd">            The desired data-type for the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return at tensor of zeros with the same shape and type as a given tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="n">diagnoal</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a 2-D tensor with the elements of `diagonal` on the diagonal and zeros elsewhere.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        diagonal : 1-D tensor</span>
<span class="sd">            diagonnal elements of the 2-D tensor to construct.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">eye</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a 2-D tensor with ones on the diagonal and zeros elsewhere.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        N : int</span>
<span class="sd">            Number of rows in the output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">where</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return elements, either from `x` or `y`, depending on `condition`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        condition : tensor</span>
<span class="sd">            When True, yield element from `x`, otherwise from `y`.</span>
<span class="sd">        x, y : tensor</span>
<span class="sd">            Values from which to choose.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">clip</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">a_min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">a_max</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Clip the values of a tensor to within an interval.</span>

<span class="sd">        Given an interval, values outside the interval are clipped to the interval</span>
<span class="sd">        edges.  For example, if an interval of ``[0, 1]`` is specified, values</span>
<span class="sd">        smaller than 0 become 0, and values larger than 1 become 1.</span>

<span class="sd">        Not more than one of `a_min` and `a_max` may be `None`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tl.tensor</span>
<span class="sd">            The tensor.</span>
<span class="sd">        a_min : scalar, optional</span>
<span class="sd">            Minimum value. If `None`, clipping is not performed on lower bound.</span>
<span class="sd">        a_max : scalar, optional</span>
<span class="sd">            Maximum value. If `None`, clipping is not performed on upper bound.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">max</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The max value in a tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scalar</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">min</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The min value in a tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scalar</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>


    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">argmax</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The argument of the max value in a tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scalar</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">argmin</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The argument of the min value in a tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scalar</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">all</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns if all array elements in a tensor are True.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the mean of a tensor, optionally along an axis.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>
<span class="sd">        axis : int, optional</span>
<span class="sd">            If provided, the mean is computed along this axis.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out : scalar or tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">sum</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the sum of a tensor, optionally along an axis.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>
<span class="sd">        axis : int, optional</span>
<span class="sd">            If provided, the sum is computed along this axis.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out : scalar or tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">prod</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the product of a tensor, optionally along an axis.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>
<span class="sd">        axis : int, optional</span>
<span class="sd">            If provided, the product is computed along this axis.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out : scalar or tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">sign</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the element-wise sign of the given input tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out : tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">abs</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the element-wise absolute value of the given input tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out : tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">sqrt</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the element-wise sqrt of the given input tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out : tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the l-`order` norm of a tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tl.tensor</span>
<span class="sd">        order : int</span>
<span class="sd">        axis : int or tuple</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float or tensor</span>
<span class="sd">            If `axis` is provided returns a tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Dot product of two tensors.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        a, b : tensor</span>
<span class="sd">            The tensors to compute the dot product of.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Solve a linear matrix equation, or system of linear scalar equations.</span>

<span class="sd">        Computes the &quot;exact&quot; solution, `x`, of the well-determined, i.e., full</span>
<span class="sd">        rank, linear matrix equation `ax = b`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        a : tensor, shape (M, M)</span>
<span class="sd">            The coefficient matrix.</span>
<span class="sd">        b : tensor, shape (M,) or (M, K)</span>
<span class="sd">            The ordinate values.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x : tensor, shape (M,) or (M, K)</span>
<span class="sd">            Solution to the system a x = b. Returned shape is identical to `b`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">qr</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the qr factorization of a matrix.</span>

<span class="sd">        Factor the matrix `a` as *qr*, where `q` is orthonormal and `r` is</span>
<span class="sd">        upper-triangular.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        a : tensor, shape (M, N)</span>
<span class="sd">            Matrix to be factored.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Q, R : tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">stack</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Join a sequence of arrays along a new axis.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">eps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>

    <span class="k">def</span> <span class="nf">finfo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">conj</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the complex conjugate, element-wise.</span>

<span class="sd">            The complex conjugate of a complex number is obtained by changing the sign of its imaginary part.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>


    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">sort</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">descending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a sorted copy of an array</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensor</span>
<span class="sd">            An N-D tensor</span>
<span class="sd">        axis : int or None</span>
<span class="sd">            Axis along which to sort. If None, the array is flattened before sorting. The default is -1, which sorts along the last axis.</span>
<span class="sd">        descending : bool</span>
<span class="sd">            If True, values are sorted in descending order, otherwise in ascending.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        sorted_tensor : tensor</span>
<span class="sd">            An N-D array, sorted copy of input tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">einsum</span><span class="p">(</span><span class="n">subscripts</span><span class="p">,</span> <span class="o">*</span><span class="n">operands</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Evaluates the Einstein summation convention on the operands.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        subscripts : str</span>
<span class="sd">            Specifies the subscripts for summation.</span>

<span class="sd">        *operands : list of tensors</span>
<span class="sd">            tensors for the operation</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output : ndarray</span>
<span class="sd">            The calculation based on the Einstein summation convention</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">moveaxis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">destination</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Move axes of a tensor to new positions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tl.tensor</span>
<span class="sd">        source : int or sequence of int</span>
<span class="sd">            Original positions of the axes to move. These must be unique.</span>
<span class="sd">        destination : int or sequence of int</span>
<span class="sd">            Destination positions for each of the original axes. These must also be</span>
<span class="sd">            unique.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">tensor</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">source</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">source</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">source</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">destination</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">destination</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">destination</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">axes</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Source should verify 0 &lt;= source &lt; tensor.ndim&#39;</span>
                             <span class="s1">&#39;Got </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">source</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">axes</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">destination</span><span class="p">,</span> <span class="n">source</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Destination should verify 0 &lt;= destination &lt; tensor.ndim&#39;</span>
                             <span class="s1">&#39;Got </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">destination</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">kron</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Kronecker product of two tensors.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        a, b : tensor</span>
<span class="sd">            The tensors to compute the kronecker product of.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">s3</span><span class="p">,</span> <span class="n">s4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">s4</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="p">(</span><span class="n">s1</span> <span class="o">*</span> <span class="n">s3</span><span class="p">,</span> <span class="n">s2</span> <span class="o">*</span> <span class="n">s4</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">kr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">matrices</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Khatri-Rao product of a list of matrices</span>

<span class="sd">        This can be seen as a column-wise kronecker product.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        matrices : list of tensors</span>
<span class="sd">            List of 2D tensors with the same number of columns, i.e.::</span>

<span class="sd">                for i in len(matrices):</span>
<span class="sd">                    matrices[i].shape = (n_i, m)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        khatri_rao_product : tensor of shape ``(prod(n_i), m)``</span>
<span class="sd">            Where ``prod(n_i) = prod([m.shape[0] for m in matrices])`` (i.e. the</span>
<span class="sd">            product of the number of rows of all the matrices in the product.)</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Mathematically:</span>

<span class="sd">        .. math::</span>
<span class="sd">            \\text{If every matrix } U_k \\text{ is of size } (I_k \\times R),\\\\</span>
<span class="sd">            \\text{Then } \\left(U_1 \\bigodot \\cdots \\bigodot U_n \\right) \\\\</span>
<span class="sd">            text{ is of size } (\\prod_{k=1}^n I_k \\times R)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">matrices</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;kr requires a list of at least 2 matrices, but </span><span class="si">{}</span><span class="s1"> &#39;</span>
                            <span class="s1">&#39;given.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matrices</span><span class="p">)))</span>

        <span class="n">n_col</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">matrices</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">res</span> <span class="o">=</span> <span class="n">matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">res</span> <span class="o">=</span> <span class="n">matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
            <span class="n">s3</span><span class="p">,</span> <span class="n">s4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">s2</span> <span class="o">==</span> <span class="n">s4</span> <span class="o">==</span> <span class="n">n_col</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;All matrices should have the same number of columns.&#39;</span><span class="p">)</span>

            <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">s2</span><span class="p">))</span>
            <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="n">s4</span><span class="p">))</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_col</span><span class="p">))</span>

        <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">res</span><span class="o">*</span><span class="n">m</span>

    <span class="k">def</span> <span class="nf">partial_svd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">n_eigenvecs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes a fast partial SVD on `matrix`</span>

<span class="sd">        If `n_eigenvecs` is specified, sparse eigendecomposition is used on</span>
<span class="sd">        either matrix.dot(matrix.T) or matrix.T.dot(matrix).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        matrix : tensor</span>
<span class="sd">            A 2D tensor.</span>
<span class="sd">        n_eigenvecs : int, optional, default is None</span>
<span class="sd">            If specified, number of eigen[vectors-values] to return.</span>
<span class="sd">        random_state: {None, int, np.random.RandomState}</span>
<span class="sd">            If specified, use it for sampling starting vector in a partial SVD(scipy.sparse.linalg.eigsh)</span>
<span class="sd">        **kwargs : optional</span>
<span class="sd">            kwargs are used to absorb the difference of parameters among the other SVD functions</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        U : 2-D tensor, shape (matrix.shape[0], n_eigenvecs)</span>
<span class="sd">            Contains the right singular vectors</span>
<span class="sd">        S : 1-D tensor, shape (n_eigenvecs, )</span>
<span class="sd">            Contains the singular values of `matrix`</span>
<span class="sd">        V : 2-D tensor, shape (n_eigenvecs, matrix.shape[1])</span>
<span class="sd">            Contains the left singular vectors</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check that matrix is... a matrix!</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;matrix be a matrix. matrix.ndim is </span><span class="si">%d</span><span class="s1"> != 2&#39;</span>
                             <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">matrix</span><span class="p">))</span>

        <span class="n">ctx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>
        <span class="n">is_numpy</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_numpy</span><span class="p">:</span>
            <span class="n">matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>

        <span class="c1"># Choose what to do depending on the params</span>
        <span class="n">dim_1</span><span class="p">,</span> <span class="n">dim_2</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">dim_1</span> <span class="o">&lt;=</span> <span class="n">dim_2</span><span class="p">:</span>
            <span class="n">min_dim</span> <span class="o">=</span> <span class="n">dim_1</span>
            <span class="n">max_dim</span> <span class="o">=</span> <span class="n">dim_2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">min_dim</span> <span class="o">=</span> <span class="n">dim_2</span>
            <span class="n">max_dim</span> <span class="o">=</span> <span class="n">dim_1</span>

        <span class="k">if</span> <span class="n">n_eigenvecs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Default on standard SVD</span>
            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_eigenvecs</span><span class="p">],</span> <span class="n">S</span><span class="p">[:</span><span class="n">n_eigenvecs</span><span class="p">],</span> <span class="n">V</span><span class="p">[:</span><span class="n">n_eigenvecs</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">elif</span> <span class="n">min_dim</span> <span class="o">&lt;=</span> <span class="n">n_eigenvecs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">max_dim</span> <span class="o">&lt;</span> <span class="n">n_eigenvecs</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">((</span><span class="s1">&#39;Trying to compute SVD with n_eigenvecs=</span><span class="si">{0}</span><span class="s1">, which &#39;</span>
                               <span class="s1">&#39;is larger than max(matrix.shape)=</span><span class="si">{1}</span><span class="s1">. Setting &#39;</span>
                               <span class="s1">&#39;n_eigenvecs to </span><span class="si">{1}</span><span class="s1">&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_eigenvecs</span><span class="p">,</span> <span class="n">max_dim</span><span class="p">))</span>
                <span class="n">n_eigenvecs</span> <span class="o">=</span> <span class="n">max_dim</span>
            <span class="k">if</span> <span class="n">n_eigenvecs</span> <span class="o">&gt;</span> <span class="n">min_dim</span><span class="p">:</span>
                <span class="n">full_matrices</span><span class="o">=</span><span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span>
            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="n">full_matrices</span><span class="p">)</span>
            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_eigenvecs</span><span class="p">],</span> <span class="n">S</span><span class="p">[:</span><span class="n">n_eigenvecs</span><span class="p">],</span> <span class="n">V</span><span class="p">[:</span><span class="n">n_eigenvecs</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># We can perform a partial SVD</span>
            <span class="c1"># construct np.random.RandomState for sampling a starting vector</span>
            <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># if random_state is not specified, do not initialize a starting vector</span>
                <span class="n">v0</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">random_state</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">rns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
                <span class="c1"># initilize with [-1, 1] as in ARPACK</span>
                <span class="n">v0</span> <span class="o">=</span> <span class="n">rns</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">min_dim</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">random_state</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">):</span>
                <span class="c1"># initilize with [-1, 1] as in ARPACK</span>
                <span class="n">v0</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">min_dim</span><span class="p">)</span>

            <span class="c1"># First choose whether to use X * X.T or X.T *X</span>
            <span class="k">if</span> <span class="n">dim_1</span> <span class="o">&lt;</span> <span class="n">dim_2</span><span class="p">:</span>
                <span class="n">S</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">matrix</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">conj</span><span class="p">()),</span> <span class="n">k</span><span class="o">=</span><span class="n">n_eigenvecs</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;LM&#39;</span><span class="p">,</span> <span class="n">v0</span><span class="o">=</span><span class="n">v0</span>
                <span class="p">)</span>
                <span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
                <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">conj</span><span class="p">(),</span> <span class="n">U</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">S</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">conj</span><span class="p">(),</span> <span class="n">matrix</span><span class="p">),</span> <span class="n">k</span><span class="o">=</span><span class="n">n_eigenvecs</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;LM&#39;</span><span class="p">,</span> <span class="n">v0</span><span class="o">=</span><span class="n">v0</span>
                <span class="p">)</span>
                <span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
                <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span> <span class="o">*</span>  <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">S</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">S</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

            <span class="c1"># WARNING: here, V is still the transpose of what it should be</span>
            <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">S</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">V</span><span class="p">[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">V</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_numpy</span><span class="p">:</span>
            <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="o">**</span><span class="n">ctx</span><span class="p">)</span>
            <span class="n">S</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="o">**</span><span class="n">ctx</span><span class="p">)</span>
            <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="o">**</span><span class="n">ctx</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span>

    <span class="k">def</span> <span class="nf">truncated_svd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">n_eigenvecs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes a truncated SVD on `matrix` using pytorch&#39;s SVD</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        matrix : 2D-array</span>
<span class="sd">        n_eigenvecs : int, optional, default is None</span>
<span class="sd">            if specified, number of eigen[vectors-values] to return</span>
<span class="sd">        **kwargs : optional</span>
<span class="sd">            kwargs are used to absorb the difference of parameters among the other SVD functions</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        U : 2D-array</span>
<span class="sd">            of shape (matrix.shape[0], n_eigenvecs)</span>
<span class="sd">            contains the right singular vectors</span>
<span class="sd">        S : 1D-array</span>
<span class="sd">            of shape (n_eigenvecs, )</span>
<span class="sd">            contains the singular values of `matrix`</span>
<span class="sd">        V : 2D-array</span>
<span class="sd">            of shape (n_eigenvecs, matrix.shape[1])</span>
<span class="sd">            contains the left singular vectors</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dim_1</span><span class="p">,</span> <span class="n">dim_2</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">dim_1</span> <span class="o">&lt;=</span> <span class="n">dim_2</span><span class="p">:</span>
            <span class="n">min_dim</span> <span class="o">=</span> <span class="n">dim_1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">min_dim</span> <span class="o">=</span> <span class="n">dim_2</span>

        <span class="k">if</span> <span class="n">n_eigenvecs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">n_eigenvecs</span> <span class="o">&gt;</span> <span class="n">min_dim</span><span class="p">:</span>
            <span class="n">full_matrices</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">full_matrices</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_eigenvecs</span><span class="p">],</span> <span class="n">S</span><span class="p">[:</span><span class="n">n_eigenvecs</span><span class="p">],</span> <span class="n">V</span><span class="p">[:</span><span class="n">n_eigenvecs</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span>

    <span class="n">index</span> <span class="o">=</span> <span class="n">Index</span><span class="p">()</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">index_update</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates the value of tensors in the specified indices</span>
<span class="sd">            Should be used as::</span>

<span class="sd">                index_update(tensor, tensorly.index[:, 3:5], values)</span>

<span class="sd">            Equivalent of::</span>
<span class="sd">            </span>
<span class="sd">                tensor[:, 3:5] = values</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : tensorly.tensor</span>
<span class="sd">            intput tensor which values to update</span>
<span class="sd">        indices : tensorly.index</span>
<span class="sd">            indices to update</span>
<span class="sd">        values : tensorly.tensor</span>
<span class="sd">            values to use to fill tensor[indices]</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tensor</span>
<span class="sd">            updated tensor</span>

<span class="sd">        Example</span>
<span class="sd">        -------</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; import tensorly as tl</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; tensor = tl.tensor([[1, 2, 3], [4, 5, 6]])</span>
<span class="sd">        &gt;&gt;&gt; cpy = tensor.copy()</span>
<span class="sd">        &gt;&gt;&gt; tensor[:, 1] = 0</span>
<span class="sd">        &gt;&gt;&gt; tensor</span>
<span class="sd">        array([[1, 0, 3],</span>
<span class="sd">                [4, 0, 6]])</span>
<span class="sd">        &gt;&gt;&gt; tl.index_update(tensor, tl.index[:, 1], 0)</span>
<span class="sd">        array([[1, 0, 3],</span>
<span class="sd">               [4, 0, 6]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tensor</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">values</span>
        <span class="k">return</span> <span class="n">tensor</span>
</pre></div>

        </div>

            
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    
</nav>

        

      </section>

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2016 - 2021, TensorLy Developers.<br/>
        </div>
    </div>
  </footer>

    </div>

        
    

    

  </div>
  </div>

  <!-- Include here scripts that need to be added after the page is loaded -->
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>