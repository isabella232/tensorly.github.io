


<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">

        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta name="keywords" content="tensor learning, tensor decomposition, tensor operations">
        <meta name="description" content="TensorLy: Tensor learning in Python">

        
        <meta name="author" content="Jean Kossaifi">
        <title>TensorLy: Tensor learning in Python</title>
        

        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="../../../_static/bulma.min.css" />
        <link rel="stylesheet" type="text/css" href="../../../_static/base.min.css" />
        <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />

        
        

        
        
    </head>

    <body>
        
        <nav class="navbar is-dark has-shadow top" id="top">
    <div class="navbar-brand">
        <a class="navbar-item navbar-title" href="../../../home.html">
            TensorLy
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="../../../index.html">
            <i class="fa fa-home" aria-hidden="true"></i>
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
            <span class="icon"><i class="fa fa-github"></i></span>
        </a>

		<span class="navbar-burger" data-target="NavbarMenu" >
			<span></span>
			<span></span>
			<span></span>
		</span>

    </div>

	<div id="NavbarMenu" class="navbar-menu">
		<div class="navbar-start">

			<a class="navbar-item" href="../../../installation.html">
				Install
			</a>
			<a class="navbar-item" href="../../../user_guide/index.html">
				User guide
			</a>
			<a class="navbar-item" href="../../../modules/api.html">
				API
			</a>
			<a class="navbar-item" href="../../../auto_examples/index.html">
				Examples
			</a>
			<a class="navbar-item" href="../../../authors.html">
				People
			</a>
			<a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
				Notebooks
			</a>

		</div>

		<div class="navbar-end">
			<a class="navbar-item is-tab tooltip is-hidden-touch" href="../../../index.html">
				<i class="fa fa-home" aria-hidden="true"></i>
				<span class="tooltiptext">Home page</span>
			</a>

			<a class="navbar-item is-tab tooltip is-hidden-touch" href="https://github.com/tensorly/tensorly" target="_blank">
				<span class="tooltiptext">Open project on Github</span>
				<span class="icon"><i class="fa fa-github"></i></span>
			</a>

		</div>
    </div>
</nav>
 

        
        <div class="columns">
            
            <div class="column is-one-quarter is-hidden-mobile aside">
                <div class="sidebar" id="sidebar">
                    
                    <div class="search">
                        <div class="search-title">
                            Search in TensorLy
                        </div>

                        <script>
                          (function() {
                            var cx = '002285679029256671182:5tfqz3cvmm8';
                            var gcse = document.createElement('script');
                            gcse.type = 'text/javascript';
                            gcse.async = true;
                            gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
                            var s = document.getElementsByTagName('script')[0];
                            s.parentNode.insertBefore(gcse, s);
                          })();
                        </script>
                        <gcse:searchbox-only></gcse:searchbox-only>
                        
                    </div>

                    <div class="toc">
                    
                    
                    
                    
                        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installing tensorly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide/index.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Gallery of examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../development_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/JeanKossaifi/tensorly-notebooks">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../authors.html">People</a></li>
</ul>

                    
                    
                    </div>
                    
                </div>
            </div>

            
            <div class="column is-three-quarters main-column">
                <div class="content main-content">

                    

  <h1>Source code for tensorly.backend.numpy_backend</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Core tensor operations.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">testing</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.linalg</span>
<span class="kn">import</span> <span class="nn">scipy.sparse.linalg</span>

<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">reshape</span><span class="p">,</span> <span class="n">moveaxis</span><span class="p">,</span> <span class="n">where</span><span class="p">,</span> <span class="n">copy</span><span class="p">,</span> <span class="n">transpose</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">arange</span><span class="p">,</span> <span class="n">ones</span><span class="p">,</span> <span class="n">zeros</span><span class="p">,</span> <span class="n">zeros_like</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">dot</span><span class="p">,</span> <span class="n">kron</span><span class="p">,</span> <span class="n">concatenate</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="nb">max</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="n">maximum</span><span class="p">,</span> <span class="nb">all</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="nb">sum</span><span class="p">,</span> <span class="n">sign</span><span class="p">,</span> <span class="nb">abs</span><span class="p">,</span> <span class="n">prod</span><span class="p">,</span> <span class="n">sqrt</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="k">import</span> <span class="n">solve</span><span class="p">,</span> <span class="n">qr</span>

<span class="c1"># Author: Jean Kossaifi</span>

<span class="c1"># License: BSD 3 clause</span>


<div class="viewcode-block" id="context"><a class="viewcode-back" href="../../../modules/generated/tensorly.context.html#tensorly.context">[docs]</a><span class="k">def</span> <span class="nf">context</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the context of a tensor</span>

<span class="sd">        Creates a dictionary of the parameters characterising the tensor</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor : tensorly.tensor</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    context : dict</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tensorly as tl</span>
<span class="sd">    Using numpy backend.</span>

<span class="sd">    Imagine you have an existing tensor `tensor`:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; tensor = tl.tensor([0, 1, 2], dtype=np.float32)</span>

<span class="sd">    The context, here, will simply be the dtype:</span>

<span class="sd">    &gt;&gt;&gt; tl.context(tensor)</span>
<span class="sd">    {&#39;dtype&#39;: dtype(&#39;float32&#39;)}</span>
<span class="sd">    </span>
<span class="sd">    Note that, if you were using, say, PyTorch, the context would also</span>
<span class="sd">    include the device (i.e. CPU or GPU) and device ID.</span>

<span class="sd">    If you want to create a new tensor in the same context, use this context:</span>

<span class="sd">    &gt;&gt;&gt; new_tensor = tl.tensor([1, 2, 3], **tl.context(tensor))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;dtype&#39;</span><span class="p">:</span><span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">}</span></div>

<span class="k">def</span> <span class="nf">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tensor class</span>
<span class="sd">        </span>
<span class="sd">        Returns a tensor on the specified context, depending on the backend</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>


<div class="viewcode-block" id="to_numpy"><a class="viewcode-back" href="../../../modules/generated/tensorly.to_numpy.html#tensorly.to_numpy">[docs]</a><span class="k">def</span> <span class="nf">to_numpy</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a copy of the tensor as a NumPy array</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor : tl.tensor</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy_tensor : numpy.ndarray</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span></div>

<span class="k">def</span> <span class="nf">assert_array_equal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">testing</span><span class="o">.</span><span class="n">assert_array_equal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">assert_array_almost_equal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">to_numpy</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">assert_raises</span> <span class="o">=</span> <span class="n">testing</span><span class="o">.</span><span class="n">assert_raises</span>
<span class="n">assert_equal</span> <span class="o">=</span> <span class="n">testing</span><span class="o">.</span><span class="n">assert_equal</span>
<span class="n">assert_</span> <span class="o">=</span> <span class="n">testing</span><span class="o">.</span><span class="n">assert_</span>

<span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>

<span class="k">def</span> <span class="nf">ndim</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndim</span>

<span class="k">def</span> <span class="nf">clip</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">a_min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">a_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">a_min</span><span class="p">,</span> <span class="n">a_max</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the l-`order` norm of tensor</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor : ndarray</span>
<span class="sd">    order : int</span>
<span class="sd">    axis : int or tuple</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float or tensor</span>
<span class="sd">        If `axis` is provided returns a tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># handle difference in default axis notation</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="p">():</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">order</span> <span class="o">==</span> <span class="s1">&#39;inf&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tensor</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">order</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tensor</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">order</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tensor</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span><span class="o">**</span><span class="n">order</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">order</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">kr</span><span class="p">(</span><span class="n">matrices</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Khatri-Rao product of a list of matrices</span>

<span class="sd">        This can be seen as a column-wise kronecker product.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    matrices : ndarray list</span>
<span class="sd">        list of matrices with the same number of columns, i.e.::</span>

<span class="sd">            for i in len(matrices):</span>
<span class="sd">                matrices[i].shape = (n_i, m)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    khatri_rao_product: matrix of shape ``(prod(n_i), m)``</span>
<span class="sd">        where ``prod(n_i) = prod([m.shape[0] for m in matrices])``</span>
<span class="sd">        i.e. the product of the number of rows of all the matrices in the product.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Mathematically:</span>

<span class="sd">    .. math::</span>
<span class="sd">         \\text{If every matrix } U_k \\text{ is of size } (I_k \\times R),\\\\</span>
<span class="sd">         \\text{Then } \\left(U_1 \\bigodot \\cdots \\bigodot U_n \\right) \\text{ is of size } (\\prod_{k=1}^n I_k \\times R)</span>

<span class="sd">    A more intuitive but slower implementation is::</span>

<span class="sd">        kr_product = np.zeros((n_rows, n_columns))</span>
<span class="sd">        for i in range(n_columns):</span>
<span class="sd">            cum_prod = matrices[0][:, i]  # Acuumulates the khatri-rao product of the i-th columns</span>
<span class="sd">            for matrix in matrices[1:]:</span>
<span class="sd">                cum_prod = np.einsum(&#39;i,j-&gt;ij&#39;, cum_prod, matrix[:, i]).ravel()</span>
<span class="sd">            # the i-th column corresponds to the kronecker product of all the i-th columns of all matrices:</span>
<span class="sd">            kr_product[:, i] = cum_prod</span>

<span class="sd">        return kr_product</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_columns</span> <span class="o">=</span> <span class="n">matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">n_factors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">matrices</span><span class="p">)</span>

    <span class="n">start</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)</span>
    <span class="n">common_dim</span> <span class="o">=</span> <span class="s1">&#39;z&#39;</span>
    <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">chr</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_factors</span><span class="p">))</span>
    <span class="n">source</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="n">common_dim</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">target</span><span class="p">)</span>
    <span class="n">operation</span> <span class="o">=</span> <span class="n">source</span><span class="o">+</span><span class="s1">&#39;-&gt;&#39;</span><span class="o">+</span><span class="n">target</span><span class="o">+</span><span class="n">common_dim</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">operation</span><span class="p">,</span> <span class="o">*</span><span class="n">matrices</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_columns</span><span class="p">))</span>

<div class="viewcode-block" id="partial_svd"><a class="viewcode-back" href="../../../modules/generated/tensorly.partial_svd.html#tensorly.partial_svd">[docs]</a><span class="k">def</span> <span class="nf">partial_svd</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">n_eigenvecs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes a fast partial SVD on `matrix`</span>

<span class="sd">        if `n_eigenvecs` is specified, sparse eigendecomposition</span>
<span class="sd">        is used on either matrix.dot(matrix.T) or matrix.T.dot(matrix)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    matrix : 2D-array</span>
<span class="sd">    n_eigenvecs : int, optional, default is None</span>
<span class="sd">        if specified, number of eigen[vectors-values] to return</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    U : 2D-array</span>
<span class="sd">        of shape (matrix.shape[0], n_eigenvecs)</span>
<span class="sd">        contains the right singular vectors</span>
<span class="sd">    S : 1D-array</span>
<span class="sd">        of shape (n_eigenvecs, )</span>
<span class="sd">        contains the singular values of `matrix`</span>
<span class="sd">    V : 2D-array</span>
<span class="sd">        of shape (n_eigenvecs, matrix.shape[1])</span>
<span class="sd">        contains the left singular vectors</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check that matrix is... a matrix!</span>
    <span class="k">if</span> <span class="n">matrix</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;matrix be a matrix. matrix.ndim is </span><span class="si">{}</span><span class="s1"> != 2&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">matrix</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>

    <span class="c1"># Choose what to do depending on the params</span>
    <span class="n">dim_1</span><span class="p">,</span> <span class="n">dim_2</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">dim_1</span> <span class="o">&lt;=</span> <span class="n">dim_2</span><span class="p">:</span>
        <span class="n">min_dim</span> <span class="o">=</span> <span class="n">dim_1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">min_dim</span> <span class="o">=</span> <span class="n">dim_2</span>

    <span class="k">if</span> <span class="n">n_eigenvecs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">n_eigenvecs</span> <span class="o">&gt;=</span> <span class="n">min_dim</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">n_eigenvecs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">n_eigenvecs</span> <span class="o">&gt;</span> <span class="n">min_dim</span><span class="p">:</span>
            <span class="n">full_matrices</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">full_matrices</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># Default on standard SVD</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="n">full_matrices</span><span class="p">)</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_eigenvecs</span><span class="p">],</span> <span class="n">S</span><span class="p">[:</span><span class="n">n_eigenvecs</span><span class="p">],</span> <span class="n">V</span><span class="p">[:</span><span class="n">n_eigenvecs</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># We can perform a partial SVD</span>
        <span class="c1"># First choose whether to use X * X.T or X.T *X</span>
        <span class="k">if</span> <span class="n">dim_1</span> <span class="o">&lt;</span> <span class="n">dim_2</span><span class="p">:</span>
            <span class="n">S</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">matrix</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">conj</span><span class="p">()),</span> <span class="n">k</span><span class="o">=</span><span class="n">n_eigenvecs</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;LM&#39;</span><span class="p">)</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
            <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">conj</span><span class="p">(),</span> <span class="n">U</span> <span class="o">*</span> <span class="mi">1</span><span class="o">/</span><span class="n">S</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">conj</span><span class="p">(),</span> <span class="n">matrix</span><span class="p">),</span> <span class="n">k</span><span class="o">=</span><span class="n">n_eigenvecs</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;LM&#39;</span><span class="p">)</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
            <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span><span class="o">/</span><span class="n">S</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># WARNING: here, V is still the transpose of what it should be</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">S</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">V</span><span class="p">[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span></div>
</pre></div>



                    <nav class="pagination">
    
    
    
</nav>

                </div>

                <footer class="footer">
    <div class="container has-text-centered">

        <p>
                &copy; 2016 - 2018, Jean Kossaifi.
        </p> 
    </div>
</footer>
            </div>

        </div>

        
        

        <script src="../../../_static/navigation.min.js"></script>
        <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-86209849-1', 'auto');
    ga('send', 'pageview');
</script>

    </body>
</html>