


<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">

        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta name="keywords" content="tensor learning, tensor decomposition, tensor operations">
        <meta name="description" content="TensorLy: Tensor learning in Python">

        
        <meta name="author" content="Jean Kossaifi">
        <title>TensorLy: Tensor learning in Python</title>
        

        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="../../_static/bulma.min.css" />
        <link rel="stylesheet" type="text/css" href="../../_static/base.min.css" />
        <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

        
        

        
        
    </head>

    <body>
        
        <nav class="navbar is-dark has-shadow top" id="top">
    <div class="navbar-brand">
        <a class="navbar-item navbar-title" href="../../index.html">
            TensorLy
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="../../index.html">
            <i class="fa fa-home" aria-hidden="true"></i>
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
            <span class="icon"><i class="fa fa-github"></i></span>
        </a>

		<span class="navbar-burger" data-target="NavbarMenu" >
			<span></span>
			<span></span>
			<span></span>
		</span>
    </div>

	<div id="NavbarMenu" class="navbar-menu">
		<div class="navbar-start">

			<a class="navbar-item" href="../../installation.html">
				Install
			</a>
			<a class="navbar-item" href="../../user_guide/index.html">
				User Guide
			</a>
			<a class="navbar-item" href="../../modules/api.html">
				API
			</a>
			<a class="navbar-item" href="../../auto_examples/index.html">
				Examples
			</a>
			<a class="navbar-item" href="../../about.html">
				About Us
			</a>
			<a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
				Notebooks
			</a>

		</div>

		<div class="navbar-end">
			<a class="navbar-item is-tab tooltip is-hidden-touch" href="../../index.html">
				<i class="fa fa-home" aria-hidden="true"></i>
				<span class="tooltiptext">Home page</span>
			</a>

			<a class="navbar-item is-tab tooltip is-hidden-touch" href="https://github.com/tensorly/tensorly" target="_blank">
				<span class="tooltiptext">Open project on Github</span>
				<span class="icon"><i class="fa fa-github"></i></span>
			</a>

		</div>
    </div>
</nav>
 

        
        <div class="columns">

                
            <div class="column is-one-quarter is-hidden-mobile aside">
    <div class="sidebar" id="sidebar">
        
        <div class="search">
            <div class="search-title">
                Search in TensorLy
            </div>

            <script>
              (function() {
                var cx = '002285679029256671182:5tfqz3cvmm8';
                var gcse = document.createElement('script');
                gcse.type = 'text/javascript';
                gcse.async = true;
                gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
                var s = document.getElementsByTagName('script')[0];
                s.parentNode.insertBefore(gcse, s);
              })();
            </script>
            <gcse:searchbox-only></gcse:searchbox-only>
            
        </div>

        <div class="toc">
        
        
        
        
            <ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installing tensorly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/index.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Gallery of examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/JeanKossaifi/tensorly-notebooks">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">About us</a></li>
</ul>

        
        
        </div>
        
    </div>
</div>

                
                <div class="column is-three-quarters main-column">
            


            
                <div class="content main-content">

                    

  <h1>Source code for tensorly.tt_tensor</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Core operations on tensors in Tensor-Train (TT) format, also known as Matrix-Product-State (MPS)</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="kn">from</span> <span class="nn">._factorized_tensor</span> <span class="kn">import</span> <span class="n">FactorizedTensor</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">DefineDeprecated</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">brentq</span>

<span class="k">def</span> <span class="nf">_validate_tt_tensor</span><span class="p">(</span><span class="n">tt_tensor</span><span class="p">):</span>
    <span class="n">factors</span> <span class="o">=</span> <span class="n">tt_tensor</span>
    <span class="n">n_factors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">n_factors</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;A Tensor-Train (MPS) tensor should be composed of at least two factors and a core.&#39;</span>
                         <span class="s1">&#39;However, </span><span class="si">{}</span><span class="s1"> factor was given.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_factors</span><span class="p">))</span>

    <span class="n">rank</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">factor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">factors</span><span class="p">):</span>
        <span class="n">current_rank</span><span class="p">,</span> <span class="n">current_shape</span><span class="p">,</span> <span class="n">next_rank</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span>

        <span class="c1"># Check that factors are third order tensors</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tl</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;TT expresses a tensor as third order factors (tt-cores).</span><span class="se">\n</span><span class="s1">&#39;</span>
                             <span class="s1">&#39;However, tl.ndim(factors[</span><span class="si">{}</span><span class="s1">]) = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                 <span class="n">index</span><span class="p">,</span> <span class="n">tl</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">factor</span><span class="p">)))</span>
        <span class="c1"># Consecutive factors should have matching ranks</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">and</span> <span class="n">tl</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">factors</span><span class="p">[</span><span class="n">index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])[</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="n">current_rank</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Consecutive factors should have matching ranks</span><span class="se">\n</span><span class="s1">&#39;</span>
                             <span class="s1">&#39; -- e.g. tl.shape(factors[0])[2]) == tl.shape(factors[1])[0])</span><span class="se">\n</span><span class="s1">&#39;</span>
                             <span class="s1">&#39;However, tl.shape(factor[</span><span class="si">{}</span><span class="s1">])[2] == </span><span class="si">{}</span><span class="s1"> but&#39;</span>
                             <span class="s1">&#39; tl.shape(factor[</span><span class="si">{}</span><span class="s1">])[0] == </span><span class="si">{}</span><span class="s1"> &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                              <span class="n">index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tl</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">factors</span><span class="p">[</span><span class="n">index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])[</span><span class="mi">2</span><span class="p">],</span> <span class="n">index</span><span class="p">,</span> <span class="n">current_rank</span><span class="p">))</span>
        <span class="c1"># Check for boundary conditions</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="n">current_rank</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Boundary conditions dictate factor[0].shape[0] == 1.&#39;</span>
                             <span class="s1">&#39;However, got factor[0].shape[0] = </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                              <span class="n">current_rank</span><span class="p">))</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">==</span> <span class="n">n_factors</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="n">next_rank</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Boundary conditions dictate factor[-1].shape[2] == 1.&#39;</span>
                             <span class="s1">&#39;However, got factor[</span><span class="si">{}</span><span class="s1">].shape[2] = </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                              <span class="n">n_factors</span><span class="p">,</span> <span class="n">next_rank</span><span class="p">))</span>
    
        <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_shape</span><span class="p">)</span>
        <span class="n">rank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_rank</span><span class="p">)</span>
        
    <span class="c1"># Add last rank (boundary condition)</span>
    <span class="n">rank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_rank</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>


<div class="viewcode-block" id="tt_to_tensor"><a class="viewcode-back" href="../../modules/generated/tensorly.tt_tensor.tt_to_tensor.html#tensorly.tt_tensor.tt_to_tensor">[docs]</a><span class="k">def</span> <span class="nf">tt_to_tensor</span><span class="p">(</span><span class="n">factors</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the full tensor whose TT decomposition is given by &#39;factors&#39;</span>

<span class="sd">        Re-assembles &#39;factors&#39;, which represent a tensor in TT/TT format</span>
<span class="sd">        into the corresponding full tensor</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    factors: list of 3D-arrays</span>
<span class="sd">              TT factors (known as core in TT terminology)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    output_tensor: ndarray</span>
<span class="sd">                   tensor whose TT/TT decomposition was given by &#39;factors&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">full_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">]</span>
    <span class="n">full_tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">factors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="n">full_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">factor</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="n">rank_prev</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">rank_next</span> <span class="o">=</span> <span class="n">factor</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">factor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">factor</span><span class="p">,</span> <span class="p">(</span><span class="n">rank_prev</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">full_tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">full_tensor</span><span class="p">,</span> <span class="n">factor</span><span class="p">)</span>
        <span class="n">full_tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">full_tensor</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">rank_next</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">full_tensor</span><span class="p">,</span> <span class="n">full_shape</span><span class="p">)</span></div>


<div class="viewcode-block" id="tt_to_unfolded"><a class="viewcode-back" href="../../modules/generated/tensorly.tt_tensor.tt_to_unfolded.html#tensorly.tt_tensor.tt_to_unfolded">[docs]</a><span class="k">def</span> <span class="nf">tt_to_unfolded</span><span class="p">(</span><span class="n">factors</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the unfolding matrix of a tensor given in TT (or Tensor-Train) format</span>

<span class="sd">    Reassembles a full tensor from &#39;factors&#39; and returns its unfolding matrix</span>
<span class="sd">    with mode given by &#39;mode&#39;</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    factors: list of 3D-arrays</span>
<span class="sd">              TT factors</span>
<span class="sd">    mode: int</span>
<span class="sd">          unfolding matrix to be computed along this mode</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    2-D array</span>
<span class="sd">    unfolding matrix at mode given by &#39;mode&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tl</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">tt_to_tensor</span><span class="p">(</span><span class="n">factors</span><span class="p">),</span> <span class="n">mode</span><span class="p">)</span></div>


<div class="viewcode-block" id="tt_to_vec"><a class="viewcode-back" href="../../modules/generated/tensorly.tt_tensor.tt_to_vec.html#tensorly.tt_tensor.tt_to_vec">[docs]</a><span class="k">def</span> <span class="nf">tt_to_vec</span><span class="p">(</span><span class="n">factors</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the tensor defined by its TT format (&#39;factors&#39;) into</span>
<span class="sd">       its vectorized format</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    factors: list of 3D-arrays</span>
<span class="sd">              TT factors</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    1-D array</span>
<span class="sd">    vectorized format of tensor defined by &#39;factors&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">tl</span><span class="o">.</span><span class="n">tensor_to_vec</span><span class="p">(</span><span class="n">tt_to_tensor</span><span class="p">(</span><span class="n">factors</span><span class="p">))</span></div>

<span class="k">def</span> <span class="nf">_tt_n_param</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">,</span> <span class="n">rank</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Number of parameters of a MPS decomposition for a given `rank` and full `tensor_shape`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor_shape : int tuple</span>
<span class="sd">        shape of the full tensor to decompose (or approximate)</span>
<span class="sd">    </span>
<span class="sd">    rank : tuple</span>
<span class="sd">        rank of the MPS decomposition</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    n_params : int</span>
<span class="sd">        Number of parameters of a MPS decomposition of rank `rank` of a full tensor of shape `tensor_shape`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">factor_params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">):</span>
        <span class="n">factor_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rank</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">s</span><span class="o">*</span><span class="n">rank</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">factor_params</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">validate_tt_rank</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">constant_rank</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rounding</span><span class="o">=</span><span class="s1">&#39;round&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the rank of a TT Decomposition</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor_shape : tupe</span>
<span class="sd">        shape of the tensor to decompose</span>
<span class="sd">    rank : {&#39;same&#39;, float, tuple, int}, default is same</span>
<span class="sd">        way to determine the rank, by default &#39;same&#39;</span>
<span class="sd">        if &#39;same&#39;: rank is computed to keep the number of parameters (at most) the same</span>
<span class="sd">        if float, computes a rank so as to keep rank percent of the original number of parameters</span>
<span class="sd">        if int or tuple, just returns rank</span>
<span class="sd">    constant_rank : bool, default is False</span>
<span class="sd">        * if True, the *same* rank will be chosen for each modes</span>
<span class="sd">        * if False (default), the rank of each mode will be proportional to the corresponding tensor_shape</span>

<span class="sd">        *used only if rank == &#39;same&#39; or 0 &lt; rank &lt;= 1*</span>

<span class="sd">    rounding = {&#39;round&#39;, &#39;floor&#39;, &#39;ceil&#39;}</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rank : int tuple</span>
<span class="sd">        rank of the decomposition</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">rounding</span> <span class="o">==</span> <span class="s1">&#39;ceil&#39;</span><span class="p">:</span>
        <span class="n">rounding_fun</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span>
    <span class="k">elif</span> <span class="n">rounding</span> <span class="o">==</span> <span class="s1">&#39;floor&#39;</span><span class="p">:</span>
        <span class="n">rounding_fun</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span>
    <span class="k">elif</span> <span class="n">rounding</span> <span class="o">==</span> <span class="s1">&#39;round&#39;</span><span class="p">:</span>
        <span class="n">rounding_fun</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Rounding should be round, floor or ceil, but got </span><span class="si">{</span><span class="n">rounding</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="s1">&#39;same&#39;</span><span class="p">:</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;</span> <span class="n">rank</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="n">constant_rank</span><span class="p">:</span>
        <span class="c1"># Choose the *same* rank for each mode</span>
        <span class="n">n_param_tensor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">)</span><span class="o">*</span><span class="n">rank</span>
        <span class="n">order</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">)</span>

        <span class="c1"># Border rank of 1, R_0 = R_N = 1</span>
        <span class="c1"># First and last factor of size I_0 R and I_N R</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># R_k I_k R_{k+1} = R^2 I_k</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">tensor_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># We want the number of params of decomp (=sum of params of factors)</span>
        <span class="c1"># To be equal to c = \prod_k I_k</span>
        <span class="n">c</span> <span class="o">=</span> <span class="o">-</span><span class="n">n_param_tensor</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">b</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">4</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">c</span><span class="p">)</span>
        <span class="c1"># We get the non-negative solution</span>
        <span class="n">solution</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">rounding_fun</span><span class="p">((</span><span class="o">-</span> <span class="n">b</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="p">)))</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">solution</span><span class="p">,</span> <span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">order</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>

    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;</span> <span class="n">rank</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Choose a rank proportional to the size of each mode</span>
        <span class="n">order</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">tensor_shape</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">tensor_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">c</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">)</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">b</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">4</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">c</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">((</span><span class="o">-</span> <span class="n">b</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="p">))</span>

        <span class="c1"># We get the non-negative solution</span>
        <span class="n">fraction_param</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span> <span class="n">b</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">fraction_param</span><span class="p">)</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rounding_fun</span><span class="p">(</span><span class="n">s</span><span class="o">*</span><span class="n">fraction_param</span><span class="p">)),</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">tensor_shape</span><span class="p">])</span>
        <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span> <span class="o">+</span> <span class="n">rank</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Check user input for errors</span>
        <span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_dim</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">n_dim</span><span class="o">+</span><span class="mi">1</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">rank</span><span class="p">):</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;Provided incorrect number of ranks. Should verify len(rank) == tl.ndim(tensor)+1, but len(rank) = </span><span class="si">{}</span><span class="s1"> while tl.ndim(tensor) + 1  = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">rank</span><span class="p">),</span> <span class="n">n_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">raise</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">))</span>

        <span class="c1"># Initialization</span>
        <span class="k">if</span> <span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;Provided rank[0] == </span><span class="si">{}</span><span class="s1"> but boundaring conditions dictatate rank[0] == rank[-1] == 1: setting rank[0] to 1.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">rank</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;Provided rank[-1] == </span><span class="si">{}</span><span class="s1"> but boundaring conditions dictatate rank[0] == rank[-1] == 1: setting rank[-1] to 1.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TTTensor</span><span class="p">(</span><span class="n">FactorizedTensor</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">factors</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># Will raise an error if invalid</span>
        <span class="n">shape</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="n">_validate_tt_tensor</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">factors</span> <span class="o">=</span> <span class="n">factors</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">factors</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">factors</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    
    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)):</span>
            <span class="k">yield</span> <span class="bp">self</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">factors</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;factors list : rank-</span><span class="si">{}</span><span class="s1"> matrix-product-state tensor of shape </span><span class="si">{}</span><span class="s1"> &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">message</span>
    
    <span class="k">def</span> <span class="nf">to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tt_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">to_unfolding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tt_to_unfolded</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">to_vec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tt_to_vec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>


<span class="n">mps_to_tensor</span> <span class="o">=</span> <span class="n">DefineDeprecated</span><span class="p">(</span><span class="n">deprecated_name</span><span class="o">=</span><span class="s1">&#39;mps_to_tensor&#39;</span><span class="p">,</span> <span class="n">use_instead</span><span class="o">=</span><span class="n">tt_to_tensor</span><span class="p">)</span>
<span class="n">mps_to_unfolded</span> <span class="o">=</span> <span class="n">DefineDeprecated</span><span class="p">(</span><span class="n">deprecated_name</span><span class="o">=</span><span class="s1">&#39;mps_to_unfolded&#39;</span><span class="p">,</span> <span class="n">use_instead</span><span class="o">=</span><span class="n">tt_to_unfolded</span><span class="p">)</span>
<span class="n">mps_to_vec</span> <span class="o">=</span> <span class="n">DefineDeprecated</span><span class="p">(</span><span class="n">deprecated_name</span><span class="o">=</span><span class="s1">&#39;mps_to_vec&#39;</span><span class="p">,</span> <span class="n">use_instead</span><span class="o">=</span><span class="n">tt_to_vec</span><span class="p">)</span>
<span class="n">_validate_mps_tensor</span> <span class="o">=</span> <span class="n">DefineDeprecated</span><span class="p">(</span><span class="n">deprecated_name</span><span class="o">=</span><span class="s1">&#39;_validate_mps_tensor&#39;</span><span class="p">,</span> <span class="n">use_instead</span><span class="o">=</span><span class="n">_validate_tt_tensor</span><span class="p">)</span>
</pre></div>



                    <nav class="pagination">
    
    
    
</nav>

                </div>

                <footer class="footer">
    <div class="container has-text-centered">

        <p>
                &copy; 2016 - 2020, Jean Kossaifi.
        </p> 
    </div>
</footer>
            </div>

        </div>

        
        

        <script src="../../_static/navigation.min.js"></script>
        <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-86209849-1', 'auto');
    ga('send', 'pageview');
</script>

    </body>
</html>